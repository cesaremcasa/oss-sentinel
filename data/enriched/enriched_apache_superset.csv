id,number,title,state,body,author,comments_count,labels,url,created_at,closed_at,sentiment,category,urgency
3756814641,36808,Bug: DuckDB charts fail with misleading ‚ÄúAuthentication required‚Äù error (Issue 1011),closed,"### Bug description


**Superset version:** (fill in, e.g. 6.0.0)
**Database:** DuckDB
**Deployment:** ( k8s)
**OS:** (Linux)

---

### Description

When using **DuckDB** as a database in Superset, **SQL Lab queries work**, but **creating charts in Explore always fails** with:

```
DB engine Error
Authentication required.
Issue 1011 - Superset encountered an unexpected error.
```

This error is misleading: DuckDB does **not support authentication**, and the connection itself is valid.

---

### Steps to reproduce

1. Add a DuckDB database in Superset
   Example SQLAlchemy URI:

   ```
   duckdb:///:memory:
   ```

2. Go to **SQL Lab** and run:

   ```sql
   SELECT
     i AS content_id,
     (i * 37) % 500 + 50 AS view_count
   FROM range(1, 11) AS r(i);
   ```

   ‚úÖ Query runs successfully

3. Click **Explore ‚Üí Save as Dataset** (Virtual Dataset)
   ‚úÖ Dataset is created successfully

4. Click **Create Chart** from the dataset
   ‚ùå Error occurs:

   ```
   Authentication required (Issue 1011)
   ```

---

### Expected behavior

* Superset should allow creating charts from DuckDB datasets (physical or virtual), **or**
* Superset should fail gracefully with a **clear error message** indicating that DuckDB Explore/metadata reflection is unsupported.

---

### Actual behavior

* SQL Lab works
* Dataset creation works
* Chart creation fails
* Superset throws a **misleading ‚ÄúAuthentication required‚Äù error**

---

### Additional notes / diagnosis

* This happens with:

  * File-backed DuckDB (not `:memory:`)
  * Tables, views, and virtual datasets
* Permissions and file access are correct
* The failure appears during **Explore / metadata inspection / reflection**
* The error message is incorrect and makes debugging difficult

---


### Screenshots/recordings

<img width=""1048"" height=""768"" alt=""Image"" src=""https://github.com/user-attachments/assets/54a65a67-3c20-4d90-a964-c235008144b8"" />


<img width=""1214"" height=""454"" alt=""Image"" src=""https://github.com/user-attachments/assets/65e580ac-d135-4f49-973f-8631d49f3c19"" />


### Superset version

master / latest-dev

### Python version

3.11

### Node version

20

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",DataStrategistTeam,3,"validation:required, data:databases, explore:error",https://github.com/apache/superset/issues/36808,2025-12-23T10:00:42Z,2025-12-23T14:38:53Z,negative,bug,high
3756677165,36807,Treemap chart color issue,open,"### Bug description

Bug Description: 
1. Treemap chart's coloring seems to be only categorical, and not sequential/linear.
2. There seems to be a 1px wide gap around the key and or value text.

- Superset 4.1.1: Have sequential/linear coloring, did not have the gap.  
- Superset 4.1.4: Categorical coloring only, did not have the gap.
- Superset 6.0.0: Categorical coloring only, have the 1px gap.

Changing Color Scheme had no effect beyond changing the colors used. No custom CSS were used.
I could test other versions, if that would be of help.



### Screenshots/recordings

1. 6.0.0/4.1.4:

<img width=""1200"" height=""471"" alt=""Image"" src=""https://github.com/user-attachments/assets/e8673a8a-0966-448a-b57f-4636e846300a"" />

2. 4.1.1 (ideal)

<img width=""1200"" height=""471"" alt=""Image"" src=""https://github.com/user-attachments/assets/3659e923-ed50-4ad6-974c-e6fd42a5650c"" />

### Superset version

6.0.0

### Python version

3.11

### Node version

I don't know

### Browser

Chrome

### Additional context

- Error persists in Chrome and Firefox.
- No error message in browser console or in the log.
- Built custom image based on 6.0.0. Dockerfile:
```Dockerfile
 FROM apache/superset:6.0.0

 USER root

 ENV BUILD_TRANSLATIONS=""true""

 RUN apt update
 RUN apt install -y python3-dev default-libmysqlclient-dev build-essential pkg-config

 RUN . /app/.venv/bin/activate
 RUN uv pip install \
     psycopg2-binary \
     mysqlclient \
     Authlib

 USER superset
 CMD [""/app/docker/entrypoints/run-server.sh""]
```

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",IHadAFish,1,"#bug:cosmetic, viz:charts:treemap",https://github.com/apache/superset/issues/36807,2025-12-23T09:14:43Z,,negative,bug,medium
3756597441,36806,Offset metrics are not displayed as dashed lines on line chart in version 6.0.0.,open,"### Bug description

In version 6.0.0, offset metrics are no longer displayed as dashed compared to version 4.1.4, a crucial issue for us. 
The issue occurs when a chart displays only one metric; multiple metrics do not cause the problem.

We would appreciate a fix in the next minor release. Thanks.



This is version 4.1.4

<img width=""1125"" height=""661"" alt=""Image"" src=""https://github.com/user-attachments/assets/4fee8925-7ffe-4898-a689-7b0eb4fd4745"" />

And this is version 6.0.0

<img width=""1252"" height=""445"" alt=""Image"" src=""https://github.com/user-attachments/assets/87e0634d-0006-46cd-9142-4c139d15a360"" />

### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",iercan,1,"#bug:regression, viz:charts:line",https://github.com/apache/superset/issues/36806,2025-12-23T08:46:46Z,,negative,bug,high
3755142919,36798,ECharts Time Grain HOUR generates invalid SQL (DATE() dropped),open,"### Bug description

### Summary
When using **ECharts time-series charts (area chart)** with **Time Grain = HOUR**, Superset 6.x generates an **incorrect SQL expression** for the hourly bucket.

The generated SQL **drops the `DATE()` truncation**, which prevents proper aggregation and results in one row per record.

This is a **regression compared to Superset 4.1.4**.

---

### Superset version
- Superset: **6.x** (reproduced on latest 6.0.x)
- Python: 3.11
- Chart type: **ECharts ‚Äì Area Chart**
- Time grain: **HOUR (PT1H)**

---

### Database / Engine
- Tested with:
  - **StarRocks** (`starrocks://`)
  - **MySQL** (`mysql://`)
- The issue occurs **independently of the SQLAlchemy backend**.

---

### Expected behavior
For Time Grain = **HOUR**, Superset should generate a bucket that truncates minutes and seconds, for example:

```sql
DATE_ADD(DATE(col), INTERVAL HOUR(col) HOUR)
```

(or any equivalent expression that produces `YYYY-MM-DD HH:00:00`).

This correctly aggregates rows by hour.

---

### Actual behavior
Superset generates:

```sql
DATE_ADD(col, INTERVAL (HOUR(col)) HOUR)
```

This expression:
- does **not** truncate minutes/seconds
- keeps `mm:ss` from the original timestamp
- results in **no aggregation** (each row remains unique)

---

### Evidence / Analysis

- `StarRocksEngineSpec.get_time_grain_expressions()[""PT1H""]` correctly returns:

```sql
DATE_ADD(DATE({col}), INTERVAL HOUR({col}) HOUR)
```

- However, for **ECharts charts**, the SQL rendered in the final query **drops `DATE()`**.
- A marker inserted in `get_time_grain_expressions()` confirms that:
  - the mapping **is called**
  - but the expression is later **re-rendered / normalized**, losing `DATE()`

Example observed query fragment:

```sql
/* __MARK_PT1H__ */
GROUP BY
  DATE_ADD(`START_DATETIME_UTC`, INTERVAL (HOUR(`START_DATETIME_UTC`)) HOUR)
```

This proves that:
- the EngineSpec mapping is consulted
- but the final SQL is reconstructed incorrectly afterward

---

### Why this is a bug
- The expression produced by Superset does **not implement an hourly time bucket**
- It breaks all time-series aggregations at the HOUR grain
- This affects **all databases**, not only StarRocks
- Superset 4.1.4 did not exhibit this behavior

---

### Workaround
A workaround is to override the PT1H grain with a non-optimizable expression, for example:

```sql
DATE_ADD(CAST(DATE({col}) AS DATETIME), INTERVAL HOUR({col}) HOUR)
```

This prevents the renderer from dropping the truncation.

Here is the full patch to put in config file:
```python
def FLASK_APP_MUTATOR(app):
    from superset.db_engine_specs.starrocks import StarRocksEngineSpec

    orig = StarRocksEngineSpec.get_time_grain_expressions

    @classmethod
    def patched(cls):
        d = dict(orig() or {})
        d[""PT1H""] = ""DATE_ADD(CAST(DATE({col}) AS DATETIME), INTERVAL HOUR({col}) HOUR)""
        return d

    try:
        orig.cache_clear()
    except Exception:
        pass

    StarRocksEngineSpec.get_time_grain_expressions = patched
    return app
```

---

### Suggested fix
- Ensure that **ECharts time-series SQL generation respects the full expression returned by `get_time_grain_expressions()`**
- Avoid reconstructing the HOUR expression manually
- Alternatively, use a canonical implementation like:

```sql
date_trunc('hour', col)
```

where supported.

---

### Reproduction steps
1. Create a dataset with a DATETIME/TIMESTAMP column
2. Create an **ECharts Area Chart**
3. Set:
   - Time Grain = **HOUR**
4. Inspect **View query**
5. Observe `DATE_ADD(col, INTERVAL HOUR(col) HOUR)` instead of a truncated timestamp

---

### Additional notes
- Switching between `mysql://` and `starrocks://` does **not** change the behavior
- Other time grains (DAY, MONTH, YEAR) behave correctly
- This appears specific to **PT1H handling in the ECharts query pipeline**


### Screenshots/recordings

_No response_

### Superset version

6.0.0

### Python version

3.11

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",renaudk,0,#bug:regression,https://github.com/apache/superset/issues/36798,2025-12-22T20:37:07Z,,negative,bug,high
3754037172,36795,Bug(chart): Three-dot menu button alignment broken by linkHoverBg theme token,open,"## Screenshot

<img width=""405"" height=""595"" alt=""Image"" src=""https://github.com/user-attachments/assets/c0f66870-f901-45af-84bc-990d9f3a6a56"" /> 

<img width=""43"" height=""50"" alt=""Image"" src=""https://github.com/user-attachments/assets/3b7450b3-0327-4509-bd68-1412937d004a"" />

<img width=""405"" height=""591"" alt=""Image"" src=""https://github.com/user-attachments/assets/70ae913a-3a0a-443a-ab73-2001dd369e86"" />

<img width=""48"" height=""58"" alt=""Image"" src=""https://github.com/user-attachments/assets/a860b6a8-7833-4659-b405-a99deb92cb0f"" />

## Description

The three-dot menu button on chart has a visual alignment issue when a custom theme defines a `linkHoverBg` color for buttons. The icon appears off-center, pushed to the right edge of the button's hover background area.

#### Current Behavior
Default theme:
- `linkHoverBg` is transparent by default
- Button has padding-right: 0
- Icon appears visually centered ‚úÖ

Custom theme:
- `linkHoverBg` is not transparent, e.g., `rgba(0,0,0,0.04)`
- Button has padding-right: 0
- Icon appears pushed to the right edge of the hover background ‚ùå

#### Root Causes
1. CSS issue: `padding-right: 0` removes necessary spacing for the hover background
2. Semantic issue: Using `buttonStyle=""link""` for a menu toggle button (not an actual link)
3. Theme incompatibility: Custom theme tokens expose the layout flaw

#### Steps to Reproduce
1. Apply custom theme in config.py
```py
THEME_DEFAULT = {
    ""components"": {
      ""Button"": {
        ""linkHoverBg"": ""rgba(0,0,0,0.04)""
      }
    },
    ""algorithm"": ""default"",
}
THEME_DARK = {
    ""components"": {
      ""Button"": {
        ""linkHoverBg"": ""rgba(255,255,255,0.08)""
      }
    },
    ""algorithm"": ""dark"",
}
```
2. Navigate to any dashboard with charts
3. Hover over any chart's three-dot menu button (top-right corner)
4. Observe the visual defect - three-dot icon is not centered within the hover background",innovark37,3,"#bug:cosmetic, global:theming",https://github.com/apache/superset/issues/36795,2025-12-22T14:38:24Z,,negative,bug,medium
3753705417,36794,"UI/UX, Theming, Chart Extension, and Mobile Export Limitations in Apache Superset",open,"## Screenshot

<img width=""1920"" height=""1833"" alt=""Image"" src=""https://github.com/user-attachments/assets/0b6ad2e9-e9de-46cf-8edf-33b2b7e324e6"" />

<img width=""1540"" height=""797"" alt=""Image"" src=""https://github.com/user-attachments/assets/18d5abc8-1afc-4002-b7bf-255d71425e01"" />

<img width=""1016"" height=""526"" alt=""Image"" src=""https://github.com/user-attachments/assets/10837400-4d75-4664-9e0e-d779121f653b"" />

[score card - GE - EN.pdf](https://github.com/user-attachments/files/24291558/score.card.-.GE.-.EN.pdf)


---

## Description

I am facing multiple UI/UX and export-related limitations while working with **Apache Superset**, specifically when trying to:

* Reproduce a **Figma-based dashboard design**
* Apply **Ant Design themes**
* Extend **ECharts capabilities**
* Export **mobile-friendly PNG/PDF reports via email**

Despite trying various supported and suggested approaches, I am unable to achieve the expected results. Below are the detailed issues.

---

### Issue 1: Unable to Reproduce Figma Dashboard UI/UX (Layout & Styling Limitations)

I tried to closely match the dashboard UI/UX as defined in Figma, but due to Superset‚Äôs layout and styling constraints, I am unable to reproduce it accurately.

What I‚Äôve tried:

* Nested **rows and columns**
* **Markdown / Text components** for layout structuring
* Adjusting chart sizes, padding, and spacing
* Applying **global CSS overrides** for dashboard background, chart cards, and containers

Observed behavior:

* Dashboard and chart cards always render with a **plain white appearance**
* CSS changes for:

  * Background colors
  * Card coloring
  * Section grouping
    either do not apply or apply inconsistently
* Fine-grained control (pixel-perfect alignment, grouped visual sections, rich card UI) similar to Figma seems very difficult or not achievable

**Question:**
Are these UI/UX limitations expected by design in Superset, or is there a recommended approach to build **design-heavy dashboards**?

---

### Issue 2: Ant Design Theme Configuration Has No Impact on Dashboards

I attempted to customize the UI using **Ant Design themes** generated from the Ant Theme Editor:

[https://ant.design/theme-editor](https://ant.design/theme-editor)

Steps taken:

* Generated Ant Design theme tokens
* Applied the theme configuration in Superset
* Verified that Superset internally uses Ant Design

Observed behavior:

* No visible changes on dashboards or charts
* No impact on:

  * Colors
  * Typography
  * Spacing
  * Card appearance

**Questions:**

* Do Ant Design themes apply:

  * Per dashboard?
  * Per chart?
  * Only at application/template level?
* Are Ant themes expected to affect dashboard visuals at all, or only core UI elements (menus, buttons, filters)?

Currently, it appears Ant Design theming does **not** influence dashboard UI in a meaningful way.

---

### Issue 3: Limited ECharts & iFrame Embedding Errors

https://echarts.apache.org/examples/en/index.html#chart-type-funnel

Superset provides a limited set of built-in ECharts. To extend this, I attempted to embed custom ECharts using **iFrames inside Markdown**, based on community and GPT suggestions.

I modified `config.py` with the following settings:

```python
# ---- ENABLE IFRAME IN MARKDOWN ----
ALLOW_IFRAME = True
ENABLE_JINJA_TEMPLATING = True

HTML_SANITIZATION = True
HTML_SANITIZATION_SCHEMA_EXTENSIONS = {
    ""tagNames"": [""iframe""],
    ""attributes"": {
        ""iframe"": [
            ""src"",
            ""width"",
            ""height"",
            ""style"",
            ""frameborder"",
            ""allow"",
            ""allowfullscreen""
        ]
    }
}

TALISMAN_ENABLED = False
```

Observed behavior:

* Dashboards fail to render properly
* iFrames are still blocked or error out
* Security / sanitization-related errors appear (screenshots attached)

**Questions:**

* Is embedding custom ECharts via iFrame officially supported?
* Are additional CSP or security settings required?
* What is the recommended way to extend ECharts beyond Superset‚Äôs built-in options?

---

### Issue 4: Dashboard Export (Email Reports) Not Mobile-Friendly & Limited to Viewport

I am also facing major limitations with **PNG / PDF exports via Email Reports**, especially for **mobile consumption**.

#### Observed issues

1. **Minimum width limitation (~600px)**

   * Exported PNGs/PDFs appear to have a minimum width of ~600px
   * Reports are hard to read on mobile devices
   * Mobile-first dashboard layouts are not respected in exports

2. **Blank / dead space in exported images**

   * When chart data occupies a smaller area, exported images still reserve large empty space
   * Results in poor visual density and wasted screen space

3. **Only current viewport is captured**

   * If the dashboard is scrollable:

     * Only the visible viewport is captured
     * Content below the fold is missing in exports

4. **No responsive scaling for mobile**

   * Exports reuse desktop layout
   * No reflow or scaling based on device size

---

#### Expected behavior

Ideally, we are looking for:

* Ability to export the **entire scrollable dashboard**
* Control over export **width, height, resolution, or scaling**
* Better handling of:

  * Auto-sizing charts
  * Removing unused blank space
* Support or best practices for **mobile-friendly email reports**

---

#### Questions

* Is there any supported way to:

  * Export the **full dashboard**, not just the visible viewport?
  * Configure export resolution or viewport size?
* Are there configuration flags related to:

  * Screenshot dimensions
  * Mobile-friendly rendering
* Are these limitations known and expected with the current export engine?

---

## Design input

I would appreciate guidance from:

* **Superset core contributors** (platform capabilities & limitations)
* **UI/UX or design contributors** (what is realistically achievable)

Specifically, I‚Äôm looking for clarity on:

* Whether **pixel-perfect Figma replication** is feasible in Superset
* The real scope of **Ant Design theming**
* Supported approaches to:

  * Rich UI dashboards
  * Custom ECharts
  * Mobile-friendly exports

If needed, this can be treated as a **design review or design suggestion**.

Thank you for your time and guidance.
",amoljagadale-max,1,"viz:charts:echarts, dashboard:css, dashboard:design, global:theming, dashboard:export",https://github.com/apache/superset/issues/36794,2025-12-22T12:52:28Z,,negative,bug,medium
3752758950,36791,How filters work in dashboards (version 5.0.0),open,"### Bug description

When I apply a filter on one tab of a dashboard and then switch to another, some datasets stop displaying any information. We only see this behavior with table charts. (version superset 5.0.0)

![Image](https://github.com/user-attachments/assets/a3eba043-16cd-49fc-ac1e-e6a130e321c3)

### Screenshots/recordings

_No response_

### Superset version

5.0.0

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [ ] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",crazychaz,1,"validation:required, viz:charts:table, dashboard:tab, dashboard:filtersets",https://github.com/apache/superset/issues/36791,2025-12-22T08:12:55Z,,negative,bug,high
3750964730,36779,Deck.gl polygon error,open,"### Bug description

Hi, I have a lot of deck.gl polygon maps. In Superset 5.0 everything works. 


<img width=""2216"" height=""1570"" alt=""Image"" src=""https://github.com/user-attachments/assets/ffa27f9b-33d7-4f97-9b3e-1c8ba902d779"" />

In Superset 6.0.0 map is rendered, but when the mouse hovers coloured part of map I get an error.

<img width=""2904"" height=""624"" alt=""Image"" src=""https://github.com/user-attachments/assets/47133b7e-61df-449f-bd19-e44cc35aca09"" />

Thank you for your attention.
",zufolo441,15,viz:charts:deck.gl,https://github.com/apache/superset/issues/36779,2025-12-21T09:40:02Z,,negative,bug,high
3749940528,36776,Table Drill to detail by date error,open,"### Bug description

VersionÔºö6.0.0
ChartType: Table

1. Drill to detail by datetime (Time Grain is Day)
2. SQL does not run according to the logic `toStartOfDay(toDateTime(""signup_done_time"")) = toDateTime ('2025 -12-18 00:00: 00')`. It's a direct string assignment, like this
``` SQL
AND ""signup_done_time"" = '2025-11-17T00:00:00.000Z'
```

### Screenshots/recordings

<img width=""470"" height=""180"" alt=""Image"" src=""https://github.com/user-attachments/assets/050207b8-7288-4d0c-bf2c-92a2cc828e74"" />

Error: Received ClickHouse exception, code: 53, server response: Code: 53. DB::Exception: Cannot convert string 2025-12-20T00:00:00.000Z to type DateTime('Asia/Shanghai'): while executing 'FUNCTION equals(breakdown_values : 0, '2025-12-20T00:00:00.000Z' : 5) -> equals(breakdown_values, '2025-12-20T00:00:00.000Z') UInt8 : 8'. (TYPE_MISMATCH) (version 23.8.9.1) (for url http://...:8123)

<img width=""882"" height=""510"" alt=""Image"" src=""https://github.com/user-attachments/assets/49603461-f099-42bb-898f-5ebc55a484ae"" />

### Superset version

6.0.0

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",inbreaks,1,"validation:required, viz:charts:table, dashboard:drill-down",https://github.com/apache/superset/issues/36776,2025-12-20T10:57:32Z,,negative,bug,high
3749841038,36775,Sorting in filter values,open,"### Bug description

The same issue as here
https://github.com/apache/superset/issues/35008

It's about sorting Int values as String in filters
In 6.0.0RC2 it was fixed.
But in 6.0.0 it reproduces again



### Screenshots/recordings

<img width=""254"" height=""376"" alt=""Image"" src=""https://github.com/user-attachments/assets/3a517f56-2374-4efe-a076-8f7a8042ca8b"" />

### Superset version

6.0.0

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [ ] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",stanislav-dombrovskiy-dp,1,"validation:required, explore:filter",https://github.com/apache/superset/issues/36775,2025-12-20T09:21:54Z,,negative,bug,medium
3748649425,36770,Apache Doris Full Text Search Operators  has sqlglot.errors.ParseError: Invalid expression / Unexpected token,open,"### Bug description

superset_app          | 2025-12-19 19:40:41,270:INFO:superset.commands.sql_lab.execute:Triggering query_id: 78
superset_app          | 2025-12-19 19:40:41,276:WARNING:superset.views.error_handling:SupersetErrorException
superset_app          | Traceback (most recent call last):
superset_app          |   File ""/app/superset/sql/parse.py"", line 562, in _parse
superset_app          |     statements = sqlglot.parse(script, dialect=dialect)
superset_app          |   File ""/app/.venv/lib/python3.10/site-packages/sqlglot/__init__.py"", line 102, in parse
superset_app          |     return Dialect.get_or_raise(read or dialect).parse(sql, **opts)
superset_app          |   File ""/app/.venv/lib/python3.10/site-packages/sqlglot/dialects/dialect.py"", line 1083, in parse
superset_app          |     return self.parser(**opts).parse(self.tokenize(sql), sql)
superset_app          |   File ""/app/.venv/lib/python3.10/site-packages/sqlglot/parser.py"", line 1623, in parse
superset_app          |     return self._parse(
superset_app          |   File ""/app/.venv/lib/python3.10/site-packages/sqlglot/parser.py"", line 1695, in _parse
superset_app          |     self.raise_error(""Invalid expression / Unexpected token"")
superset_app          |   File ""/app/.venv/lib/python3.10/site-packages/sqlglot/parser.py"", line 1736, in raise_error
superset_app          |     raise error
superset_app          | sqlglot.errors.ParseError: Invalid expression / Unexpected token. Line 1, Col: 35.
superset_app          |   SELECT * FROM t WHERE column1 MATCH 'word1 word2'
superset_app          |
superset_app          | The above exception was the direct cause of the following exception:
superset_app          |
superset_app          | Traceback (most recent call last):
superset_app          |   File ""/app/.venv/lib/python3.10/site-packages/flask/app.py"", line 1484, in full_dispatch_request
superset_app          |     rv = self.dispatch_request()
superset_app          |   File ""/app/.venv/lib/python3.10/site-packages/flask/app.py"", line 1469, in dispatch_request
superset_app          |     return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
superset_app          |   File ""/app/.venv/lib/python3.10/site-packages/flask_appbuilder/security/decorators.py"", line 109, in wraps
superset_app          |     return f(self, *args, **kwargs)
superset_app          |   File ""/app/superset/views/base_api.py"", line 120, in wraps
superset_app          |     duration, response = time_function(f, self, *args, **kwargs)
superset_app          |   File ""/app/superset/utils/core.py"", line 1410, in time_function
superset_app          |     response = func(*args, **kwargs)
superset_app          |   File ""/app/superset/views/base_api.py"", line 92, in wraps
superset_app          |     return f(self, *args, **kwargs)
superset_app          |   File ""/app/superset/utils/log.py"", line 304, in wrapper
superset_app          |     value = f(*args, **kwargs)
superset_app          |   File ""/app/superset/sqllab/api.py"", line 406, in execute_sql_query
superset_app          |     command_result: CommandResult = command.run()
superset_app          |   File ""/app/superset/utils/decorators.py"", line 267, in wrapped
superset_app          |     return on_error(ex)
superset_app          |   File ""/app/superset/utils/decorators.py"", line 232, in on_error
superset_app          |     raise ex
superset_app          |   File ""/app/superset/utils/decorators.py"", line 260, in wrapped
superset_app          |     result = func(*args, **kwargs)
superset_app          |   File ""/app/superset/commands/sql_lab/execute.py"", line 105, in run
superset_app          |     status = self._run_sql_json_exec_from_scratch()
superset_app          |   File ""/app/superset/commands/sql_lab/execute.py"", line 154, in _run_sql_json_exec_from_scratch
superset_app          |     self._set_query_limit_if_required(rendered_query)
superset_app          |   File ""/app/superset/commands/sql_lab/execute.py"", line 220, in _set_query_limit_if_required
superset_app          |     self._set_query_limit(rendered_query)
superset_app          |   File ""/app/superset/commands/sql_lab/execute.py"", line 230, in _set_query_limit
superset_app          |     db_engine_spec.get_limit_from_sql(rendered_query),
superset_app          |   File ""/app/superset/db_engine_specs/base.py"", line 1137, in get_limit_from_sql
superset_app          |     script = SQLScript(sql, engine=cls.engine)
superset_app          |   File ""/app/superset/sql/parse.py"", line 1242, in __init__
superset_app          |     self.statements = statement_class.split_script(script, engine)
superset_app          |   File ""/app/superset/sql/parse.py"", line 602, in split_script
superset_app          |     cls(ast=ast, engine=engine) for ast in cls._parse(script, engine) if ast
superset_app          |   File ""/app/superset/sql/parse.py"", line 573, in _parse
superset_app          |     raise SupersetParseError(script, engine, **kwargs) from ex
superset_app          | superset.exceptions.SupersetParseError: Error parsing near 'MATCH' at line 1:35

### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",nico-gsantos,1,sqllab,https://github.com/apache/superset/issues/36770,2025-12-19T19:49:46Z,,negative,bug,high
3747170120,36765,Boolean filters does not work for Databricks datasets,open,"### Bug description

Creating a native filter with a boolean column causes the Databricks query to fail, likely due to an SQL translation issue.

Here is the filter we add. 

<img width=""486"" height=""222"" alt=""Image"" src=""https://github.com/user-attachments/assets/911801b7-e745-4929-949d-e9c85b0f6650"" />

And this is the error whenever we try to set any value on this filter

```
Error: [DATATYPE_MISMATCH.DATA_DIFF_TYPES] Cannot resolve ""(is_test_user IN (0))"" due to data type mismatch: Input to `in` should all be the same type, but it's [""BOOLEAN"", ""INT""]. SQLSTATE: 42K09; line 6 pos 15

```

This is the query superset sending to databricks. 

```
SELECT
  ...
FROM prod.video_coin_operation_extended
WHERE
  is_test_user IN (0)
  ...
```

I think query should have sent is as `False` rather then 0 
Tested it on master and version 6.0.0 

We worked around this issue by creating a string-type calculated column for filtering but would still appreciate a resolution.



### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [ ] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",iercan,0,data:connect:databricks,https://github.com/apache/superset/issues/36765,2025-12-19T11:25:29Z,,negative,bug,high
3745260374,36752,Make backend tests more isolated,open,"## Description

I think many people are tired of the fact that problems periodically arise during the testing phase, since some tests depend on each other. I suggest adding the `pytest-randomly` library for the backend. This will allow you to run the tests always in a different order, which will make it possible to find the consolidation of tests between each other faster.",Neko1313,0,change:backend,https://github.com/apache/superset/issues/36752,2025-12-18T23:30:50Z,,positive,feature_request,medium
3740268978,36717,Athena SQL parsing fails due to Presto dialect mapping in SQLGlot,open,"### **Bug Description**

When using AWS Athena in Superset, queries with Athena-specific syntax (e.g. USING EXTERNAL FUNCTION) fail at SQL parsing in SQL Lab.

Superset currently maps Athena to the Presto dialect in SQLGlot, which doesn‚Äôt support some Athena syntax, leading to parse errors before the query is sent to Athena.

Example of query that fails:
`USING EXTERNAL FUNCTION decrypt(data varbinary)
RETURNS VARCHAR
LAMBDA 'arn:aws:lambda:ap-south-1:123456789111:function:lambda-test'
SELECT 1`

Actual error:
`Unable to parse SQL
Error parsing near 'USING' at line 1:5`


### How to Reproduce
1. Connect Superset to AWS Athena.
2. Open SQL Lab.
3. Run the query above.
4. Observe a parsing error instead of execution in Athena.

### Expected Behavior
Superset should parse valid Athena SQL and forward it to Athena for execution.

### Actual Behavior
The SQL parser rejects the query due to incorrect Presto dialect mapping.

### Screenshots/recordings

<img width=""1725"" height=""549"" alt=""Image"" src=""https://github.com/user-attachments/assets/74a7c19b-da3e-48e9-9b50-d5e8deadc756"" />

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

Superset currently maps `""awsathena""` to the Presto SQLGlot dialect. Using the Athena SQLGlot dialect should fix this.

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [ ] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",ankitajhanwar2001,2,data:connect:athena,https://github.com/apache/superset/issues/36717,2025-12-17T20:01:38Z,,negative,bug,high
3738409912,36704,"[6.0.0rc4] The variable ""WEBDRIVER_BASEURL_USER_FRIENDLY"" can cause an error in the display of the chart ""deck.gl GeoJSON""",open,"### Bug description

When I set my variable [WEBDRIVER_BASEURL_USER_FRIENDLY = ""https://my.domain.com""] in my ""superset_config.py"" configuration file and want to create a chart in the ""deck.gl GeoJSON"" module to view points, I get an error message back.

<img width=""1289"" height=""565"" alt=""Image"" src=""https://github.com/user-attachments/assets/051a462d-7e81-4073-84fe-331d25dbeec1"" />

Apart from this graph, all others can be displayed correctly.

If I change my configuration to [WEBDRIVER_BASEURL_USER_FRIENDLY = ""http://localhost:8088""] the display of the ""deck.gl GeoJSON"" chart works.

### Screenshots/recordings

The logs are not very explicit:

`2025/12/17 11:44:24	stdout	127.0.0.1 - - [17/Dec/2025:11:44:24 +0100] ""GET //health HTTP/1.1"" 200 2 ""-"" ""curl/7.88.1""
2025/12/17 11:43:58	stdout	192.168.128.1 - - [17/Dec/2025:11:43:58 +0100] ""POST /superset/log/?explode=events HTTP/1.1"" 200 9 ""https://my.domain.com/explore/?form_data_key=idTnE7TGdYo&datasource_type=table&datasource_id=26"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36""
2025/12/17 11:43:58	stdout	192.168.128.1 - - [17/Dec/2025:11:43:58 +0100] ""PUT /api/v1/explore/form_data/idTnE7TGdYo?tab_id=79 HTTP/1.1"" 200 22 ""https://my.domain.com/explore/?form_data_key=idTnE7TGdYo&datasource_type=table&datasource_id=26"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36""
2025/12/17 11:43:57	stdout	192.168.128.1 - - [17/Dec/2025:11:43:57 +0100] ""POST /superset/explore_json/?results=true HTTP/1.1"" 200 12269 ""https://my.domain.com/explore/?form_data_key=idTnE7TGdYo&datasource_type=table&datasource_id=26"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36""
2025/12/17 11:43:57	stdout	192.168.128.1 - - [17/Dec/2025:11:43:57 +0100] ""POST /superset/explore_json/ HTTP/1.1"" 200 13059 ""https://my.domain.com/explore/?form_data_key=idTnE7TGdYo&datasource_type=table&datasource_id=26"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36""
2025/12/17 11:43:57	stderr	2025-12-17 11:43:57,823:INFO:superset.viz:Serving from cache
2025/12/17 11:43:57	stderr	2025-12-17 11:43:57,820:INFO:superset.viz:Cache key: 1b7e9e93bd661e73f564a19f62d69ab7
2025/12/17 11:43:57	stderr	2025-12-17 11:43:57,787:INFO:superset.viz:Serving from cache
2025/12/17 11:43:57	stderr	2025-12-17 11:43:57,783:INFO:superset.viz:Cache key: 1b7e9e93bd661e73f564a19f62d69ab7
2025/12/17 11:43:57	stderr	2025-12-17 11:43:57,772:WARNING:superset.views.base:Superset.explore_json This API endpoint is deprecated and will be removed in version 5.0.0
2025/12/17 11:43:57	stderr	2025-12-17 11:43:57,763:WARNING:superset.views.base:Superset.explore_json This API endpoint is deprecated and will be removed in version 5.0.0
2025/12/17 11:43:57	stdout	192.168.128.1 - - [17/Dec/2025:11:43:57 +0100] ""GET /static/assets/loading.cff8a5da.gif HTTP/1.1"" 200 0 ""https://my.domain.com/explore/?form_data_key=idTnE7TGdYo&datasource_type=table&datasource_id=26"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36""
2025/12/17 11:43:54	stdout	127.0.0.1 - - [17/Dec/2025:11:43:54 +0100] ""GET //health HTTP/1.1"" 200 2 ""-"" ""curl/7.88.1""
2025/12/17 11:43:46	stdout	192.168.128.1 - - [17/Dec/2025:11:43:46 +0100] ""POST /superset/log/?explode=events HTTP/1.1"" 200 9 ""https://my.domain.com/explore/?form_data_key=idTnE7TGdYo&datasource_type=table&datasource_id=26"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36""
2025/12/17 11:43:45	stdout	192.168.128.1 - - [17/Dec/2025:11:43:45 +0100] ""POST /api/v1/explore/form_data?tab_id=79 HTTP/1.1"" 201 22 ""https://my.domain.com/explore/?form_data_key=idTnE7TGdYo&datasource_type=table&datasource_id=26"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36""
2025/12/17 11:43:45	stdout	192.168.128.1 - - [17/Dec/2025:11:43:45 +0100] ""POST /superset/explore_json/?results=true HTTP/1.1"" 200 12269 ""https://my.domain.com/explore/?form_data_key=idTnE7TGdYo&datasource_type=table&datasource_id=26"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36""
2025/12/17 11:43:45	stdout	192.168.128.1 - - [17/Dec/2025:11:43:45 +0100] ""GET /static/assets/d3ab9294464d31db4220.chunk.js HTTP/1.1"" 200 310586 ""https://my.domain.com/explore/?form_data_key=idTnE7TGdYo&datasource_type=table&datasource_id=26"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36""
2025/12/17 11:43:45	stderr	2025-12-17 11:43:45,413:INFO:superset.viz:Serving from cache
2025/12/17 11:43:45	stderr	2025-12-17 11:43:45,412:INFO:superset.viz:Cache key: 1b7e9e93bd661e73f564a19f62d69ab7
2025/12/17 11:43:45	stdout	192.168.128.1 - - [17/Dec/2025:11:43:45 +0100] ""GET /static/assets/d8f7b62fe905b424e3e7.chunk.js HTTP/1.1"" 200 232778 ""https://my.domain.com/explore/?form_data_key=idTnE7TGdYo&datasource_type=table&datasource_id=26"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36""
2025/12/17 11:43:45	stderr	2025-12-17 11:43:45,391:WARNING:superset.views.base:Superset.explore_json This API endpoint is deprecated and will be removed in version 5.0.0
2025/12/17 11:43:45	stdout	192.168.128.1 - - [17/Dec/2025:11:43:45 +0100] ""GET /static/assets/d0aad9658f452bad0e53.chunk.js HTTP/1.1"" 200 5273 ""https://my.domain.com/explore/?form_data_key=idTnE7TGdYo&datasource_type=table&datasource_id=26"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36""`

### Superset version

master / latest-dev

### Python version

3.10

### Node version

18 or greater

### Browser

Chrome

### Additional context

Superset works with HTTP but installed behind a reverse proxy (NGINX) that provides the HTTPS protocol.

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",SupersetOdT,5,"viz:charts:geojson, viz:charts:deck.gl",https://github.com/apache/superset/issues/36704,2025-12-17T11:02:42Z,,negative,bug,high
3736314908,36683,Once a Clickhouse dataset has a schema assigned it cannot be removed,open,"### Bug description

- for superset, we use a specific clickhouse user whose default database changes every day
- we must not specify a schema when setting up datasets, though sometimes users will pick a specific database to test something
- after the dataset has been saved with a specific database name in the schema field, attempts to clear this value (by clicking the ""x"" to clear it and then saving) fail to clear the value - it appears to save successfully but if you refresh the page the value comes back

This was working correctly on Superset v3.1.3, we're seeing this behavior since upgrading to v6.0.0rc3, we also tested on v6.0.0rc4

### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.10

### Node version

Not applicable

### Browser

Not applicable

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",gfody,3,"validation:required, data:connect:clickhouse",https://github.com/apache/superset/issues/36683,2025-12-16T21:03:38Z,,negative,bug,high
3736283153,36682,CSV email reports fail with HTTP 500 when using non-default CSV delimiter (GUI CSV export works),open,"### Bug description

# üêû CSV email reports fail with HTTP 500 when using non-default CSV delimiter (GUI CSV export works)

**Superset version:** Apache Superset 5.0.0
**Deployment:** Helm chart
**Docker image:** `apachesuperset.docker.scarf.sh/apache/superset`
**Base OS:** Debian Bookworm
**Python:** 3.10
**Pandas:** default dependency
**Celery:** enabled (reports/alerts)
**Email reports:** enabled
**Locale:** `sk_SK.UTF-8` (not the root cause, listed for completeness)

**Problem description**
CSV downloads from the Superset GUI work correctly even when `CSV_EXPORT` is configured with a non-default delimiter (e.g. `;`) and decimal separator (e.g. `,`). However, CSV email reports fail with an internal server error (HTTP 500). The failure occurs only in the email reporting workflow and does not affect manual CSV exports from the UI.

**Configuration used**

```yaml
bootstrapScript: |
  #!/bin/bash

  apt-get update && \
    apt-get install -y locales && \
    apt autoremove -y && \
    apt clean
  localedef -i sk_SK -f UTF-8 sk_SK.UTF-8

  rm -rf /var/lib/apt/lists/*

  uv pip install Pillow \
    psycopg2-binary \
    cx_Oracle \
    sqlalchemy-vertica-python \
    pymssql \
    redis==4.6.0 \
    openpyxl \
    playwright \
    && playwright install-deps \
    && PLAYWRIGHT_BROWSERS_PATH=/usr/local/share/playwright-browsers playwright install chromium
```

```python
CSV_EXPORT = {
    ""encoding"": ""cp1250"",
    ""sep"": "";"",
    ""decimal"": "",""
}
```

**Steps to reproduce**

1. Deploy Apache Superset 5.0.0 using the configuration above.
2. Configure CSV export with a non-default delimiter and decimal separator as shown.
3. Create a chart with two columns.
4. Download the CSV from the Superset GUI ‚Äî works correctly.
5. Create and schedule an email report for the same chart with a CSV attachment.
6. Let the report execute via Celery, or manually trigger the endpoint used by reports:

```bash
curl -H ""Authorization: Bearer $TOKEN"" \
  ""http://superset.superset.svc.cluster.local:8088/api/v1/chart/159/data/?format=csv&type=post_processed&force=false""
```

**Actual behavior**
When the CSV is generated as part of an email report, Superset returns HTTP 500 ‚Äì Internal Server Error.

Client/API response:

```html
 curl   -H ""Authorization: Bearer $TOKEN""   ""http://superset.superset.svc.cluster.local:8088/api/v1/chart/159/data/?format=csv&type=post_processed&force=false""
<!doctype html><html lang=""en""><head><meta charset=""UTF-8""/><meta http-equiv=""X-UA-Compatible"" content=""IE=edge""/><meta name=""viewport"" content=""width=q,initial-scale=1""/><link rel=""icon"" type=""image/png"" href=""/static/assets/e3bafb62eb2592c0bb0e.png""/><link href=""https://fonts.googleapis.com/css2?family=Inter:wght@400;500&display=swap"" rel=""stylesheet""/><style>html {
        height: 100%;
      }
      body {
        color: #1985a0;
        font-family: 'Inter', sans-serif;
        height: 100%;
        margin: 0;
        display: flex;
        align-items: stretch;
      }
      h1 {
        font-weight: 600;
        font-size: 88px;
        margin: 0;
      }
      p {
        font-weight: 500;
        font-size: 24px;
        line-height: 40px;
        width: 490px;
      }
      .button {
        -webkit-appearance: button;
        -moz-appearance: button;
        appearance: button;
        background-color: #1985a0; /* Green */
        border: none;
        color: white;
        padding: 16px 38px;
        text-align: center;
        text-decoration: none;
        display: inline-block;
        font-size: 11px;
        border-radius: 4px;
        text-transform: uppercase;
      }
      .error-page-content {
        display: flex;
        flex-direction: row;
        align-items: center;
        justify-content: space-between;
        max-width: 1350px;
        margin: auto;
        width: 100%;
        padding: 56px;
      }
      img {
        width: 540px;
      }</style><title>500: Internal server error | Superset</title></head><body><div class=""error-page-content""><section><h1>Internal server error</h1><p>Sorry, something went wrong. We are fixing the mistake now. Try again later or go back to home.</p><a href=""/"" class=""button"">Back to home</a></section><img alt=""500"" src=""/static/assets/b01fb73b111d937e4c09.png"" width=""540""/></div></body></html>root@superset-worker-695fff8dbb-ssqnv:/app
```

Superset application logs:

```text
2025-12-16 21:11:00,667:WARNING:superset.views.error_handling:Exception
Traceback (most recent call last):
  File ""/app/.venv/lib/python3.10/site-packages/flask/app.py"", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
  File ""/app/.venv/lib/python3.10/site-packages/flask/app.py"", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File ""/app/superset/charts/data/api.py"", line 359, in _send_chart_response
    result = apply_client_processing(result, form_data, datasource)
  File ""/app/superset/charts/client_processing.py"", line 330, in apply_client_processing
    df = pd.read_csv(StringIO(data))
  File ""/app/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py"", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File ""pandas/_libs/parsers.pyx"", line 2029, in pandas._libs.parsers.raise_parser_error
pandas.errors.ParserError: Error tokenizing data.
C error: Expected 2 fields in line 14, saw 3
```

```text
2025-12-16 21:11:00,668:ERROR:superset.views.error_handling:
Error tokenizing data. C error: Expected 2 fields in line 14, saw 3
```

**Summary**
CSV email reports fail with HTTP 500 due to a Pandas parsing error during client-side post processing. The issue does not affect CSV downloads from the GUI and appears isolated to the email/report execution path, where `CSV_EXPORT` delimiter settings are ignored when CSV data is re-parsed.


### Screenshots/recordings

_No response_

### Superset version

5.0.0

### Python version

3.10

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",pipina,11,"data:csv, alert-reports",https://github.com/apache/superset/issues/36682,2025-12-16T20:51:59Z,,negative,bug,high
3735357562,36676,Filter box can't retrieve values when using BigQuery with required partition filter,closed,"### Bug description

We use Google BigQuery, and have enabled the setting to require partition filters (on a date column) on our tables, as our tables have multiple years of data, with billions of rows. Generally, users only want to see the last few weeks or months, and scanning the full table is both costly and can actually cause Superset to freeze as the queries take too long to execute.

Requiring the partition filter works, and we get a nice error screen when the user has not added this filter on this chart. We have set the default datetime column, and also enabled the `DEFAULT_TIME_FILTER` setting. This all works really well.

Unfortunately though, filtering on text columns now doesn't give a nice UI with the available values in the filter box. This is because the query that Superset generates to retrieve those values does not use the date filter set by the user or the `DEFAULT_TIME_FILTER` setting, and thus BigQuery rejects it because it is missing the partition filter. Users can still manually enter the values they want to see, but this is hard if you don't know beforehand which values are available. Without the required partition filter, the queries to retrieve these values would often take way too long, and would cause Superset to become unstable.

Likewise such filters break on dashboard filter sets. However, here you can configure the filter to be dependent on the other time filter (if configured), and this works pretty well. This is something we just need to explain to our users, although the error message if you don't do this could be nicer.

I think that when creating charts, the filter box should adhere to the other filters that are already configured on the chart, so you can really narrow down on the values that you want to select. Especially if they are time filters. That would solve both the required partition filter, as well as the case that the query would timeout because a full scan of the table would take too long.

### Screenshots/recordings

<img width=""383"" height=""383"" alt=""Image"" src=""https://github.com/user-attachments/assets/4e63b4e6-efda-4006-882a-9f26f32f7c7d"" />

Generated query:

```sql
SELECT DISTINCT `readable_brand_name` AS `column_values` 
FROM (SELECT * FROM `clicks`
) AS `virtual_table`
 LIMIT 10000
```

BigQuery error (UI doesn't show it, it just shows no values to select):

> Cannot query over table 'clicks' without a filter over column(s) 'event_date_cet' that can be used for partition elimination

On dashboards:

<img width=""261"" height=""219"" alt=""Image"" src=""https://github.com/user-attachments/assets/736b9a95-3bc5-4835-8dfa-79fdc436db80"" />

With the generic error:

> Network error: Network error while attempting to fetch resource

But this works really well if you make the filter dependent on the time filter:

<img width=""879"" height=""592"" alt=""Image"" src=""https://github.com/user-attachments/assets/9a4ec492-abd5-4ebe-b829-416bd8aa7ad1"" />

Generated query:

```sql
SELECT `readable_brand_name` AS `readable_brand_name` 
FROM (SELECT * FROM `clicks`
) AS `virtual_table` 
WHERE `event_date_cet` >= CAST('2025-09-16' AS DATE) AND `event_date_cet` < CAST('2025-12-16' AS DATE) GROUP BY `readable_brand_name` ORDER BY `readable_brand_name` ASC
 LIMIT 1000
```

Something like this would be nice for when creating a chart as well.

### Superset version

5.0.0

### Python version

3.11

### Node version

16

### Browser

Firefox

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",Gwildor,2,"data:connect:googlebigquery, dashboard:filterbox",https://github.com/apache/superset/issues/36676,2025-12-16T15:48:56Z,2025-12-16T16:24:29Z,negative,bug,high
3734721502,36672,[SIP] Support for CSV/Excel file uploads to ClickHouse,open,"*Please make sure you are familiar with the SIP process documented*
[here](https://github.com/apache/superset/issues/5602). The SIP will be numbered by a committer upon acceptance.

## [SIP] Proposal for implementing data upload to ClickHouse DB via CSV/Excel<title>

### Motivation

Currently, not all database engines in Superset support data upload via files. I am implementing file upload functionality for ClickHouse in my fork-project and would like to contribute it to the Superset so it can be useful for others.

### Proposed Change

1. Implement a df_to_sql method within the ClickHouseEngineSpec class in /superset/db_engine_specs/clickhouse.py. Newly created tables will use the MergeTree engine.
2. Enable the supports_file_upload flag for ClickHouseEngineSpec in the same file.

### New or Changed Public Interfaces

UI ‚Äì The ""Upload file‚Ä¶"" button in the navigation bar will become active if there are ClickHouse database connections with file uploading enabled. The upload modal window will likely remain unchanged.

### New dependencies

No new dependencies are required for this implementation.

### Migration Plan and Compatibility

No database migrations are required for this feature. It is fully backward compatible.

### Rejected Alternatives

No alternatives have been rejected at this stage.
",innovark37,1,"sip, data:connect:clickhouse, design:proposal",https://github.com/apache/superset/issues/36672,2025-12-16T13:07:24Z,,positive,feature_request,medium
3733872263,36670,Improve typography hierarchy and consistency in explore panel,open,"## Screenshot

<img width=""310"" height=""594"" alt=""Image"" src=""https://github.com/user-attachments/assets/5dd4c1b2-334e-45a0-b804-bd7ee2692949"" />

<img width=""626"" height=""672"" alt=""Image"" src=""https://github.com/user-attachments/assets/df1239e6-9338-46ab-b8f7-f440221173c5"" />

<img width=""601"" height=""917"" alt=""Image"" src=""https://github.com/user-attachments/assets/f30e2cb6-3e1b-439c-bd9c-1de9d8df7e4e"" />

## Description
There are typography inconsistencies in the widget settings/sidebar panels that affect visual hierarchy and readability. The current implementation uses multiple font weights for titles within inner blocks and inconsistent font sizes between input fields and dropdown selectors.

#### Current Issues
- Inconsistent font weights: Titles within inner settings blocks use varying font weights, creating visual noise rather than clear hierarchy
- Font size mismatch: Text inside input fields and dropdown selectors has different sizes, breaking visual alignment
- Poor contrast: The lack of consistent typography makes information blocks less scannable and structured

#### Expected Behavior
- Uniform titles: Use a single, consistent font weight for all titles within widget settings inner blocks
- Consistent inputs: Apply the same font size to text in both input fields and dropdown selectors
- Enhanced hierarchy: Create clear visual contrast between different information levels through spacing and size (not through multiple font weights)
",innovark37,0,explore:design,https://github.com/apache/superset/issues/36670,2025-12-16T09:08:45Z,,neutral,feature_request,medium
3726790188,36602,Intermittent 404 / 405 routing errors after upgrading to Superset 6.0.0rc4,open,"### Bug description

After upgrading Apache Superset to **6.0.0rc4**, we started observing intermittent routing errors during normal application usage.

The upgrade triggered the standard metadata database migration successfully. However, while using the Superset UI (navigating dashboards, charts, etc.), the application intermittently logs 404 NotFound and 405 MethodNotAllowed exceptions originating from Flask/Werkzeug routing.

These errors did not occur prior to upgrading to the 6.0.0 RC build.

### Screenshots/recordings

**Application logs show intermittent routing exceptions:**

werkzeug.exceptions.NotFound: 404 Not Found

werkzeug.exceptions.MethodNotAllowed: 405 Method Not Allowed

**Exceptions originate from Flask request routing:**

werkzeug/routing/map.py: match()
flask/ctx.py: match_request()
flask/app.py: raise_routing_exception()




**Steps to Reproduce**

Upgrade an existing Superset deployment to 6.0.0rc4

Allow metadata database migration to complete

Use the Superset UI (dashboards, charts, navigation)

Observe intermittent 404/405 routing exceptions in the application logs



### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context


This behavior was not observed on earlier Superset versions.

Since the database schema has been migrated, downgrading is not straightforward.

Seeking guidance on whether this is a known issue in the 6.0 RC builds.

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",udayv2000,5,,https://github.com/apache/superset/issues/36602,2025-12-14T05:27:54Z,,negative,bug,high
3725938499,36601,Superset new release 0.15.1 issue,open,"### Bug description

I am not seeing new release 0.15.1 in helm repo. I have newly added the repo and run repo update also. screenshot is attached for refference.

<img width=""1102"" height=""242"" alt=""Image"" src=""https://github.com/user-attachments/assets/fc739c42-599c-472e-9a33-f8ed6cc8936e"" />

### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [ ] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",GMfragrnace,4,deploy:helm,https://github.com/apache/superset/issues/36601,2025-12-13T13:01:57Z,,negative,bug,medium
3724998730,36598,Embedding fails because GuestUser is never active,open,"### Bug description

When dashboards are embedded, api calls to the following endpoints fail with `Forbidden (403)` error.
- api/v1/dashboard/{id_or_slug}
- api/v1/dashboard/{id_or_slug}/charts
- api/v1/dashboard/{id_or_slug}/datasets

After discarding all the typical misconfiguration errors, I noticed that the issue seems to originate in the fact that the `GuestUser` instance's property `is_active` always returns `False`.

Even when the `GuestUser` class has an `active` attribute always set to `True`:

```
# guest_token.py
# --------------------------------------------------

class GuestUser(AnonymousUserMixin):
    """"""
    Used as the ""anonymous"" user in case of guest authentication (embedded)
    """"""

    is_guest_user = True
>>  active = True

    @property
    def is_authenticated(self) -> bool:
        """"""
        This is set to true because guest users should be considered authenticated,
        at least in most places. The treatment of this flag is kind of inconsistent.
        """"""
        return True

    @property
    def is_anonymous(self) -> bool:
        """"""
        This is set to false because lots of code assumes that
        if user.is_anonymous, then role = Public
        But guest users need to have their own role independent of Public.
        """"""
        return False

    def __init__(self, token: GuestToken, roles: list[Role]):
        user = token[""user""]
        self.guest_token = token
        self.username = user.get(""username"", ""guest_user"")
        self.first_name = user.get(""first_name"", ""Guest"")
        self.last_name = user.get(""last_name"", ""User"")
        self.roles = roles
        self.groups: list[Group] = []  # Guest users don't belong to any groups
        self.resources = token[""resources""]
        self.rls = token.get(""rls_rules"", [])

```

The problem is that it inherits the `is_active` property from `AnonymousUserMixin`, which is always set to `False`:

```
# flask_login.mixins.py
# --------------------------------------------------

class AnonymousUserMixin:
    """"""
    This is the default object for representing an anonymous user.
    """"""

    @property
    def is_authenticated(self):
        return False

>>  @property
>>  def is_active(self):
>>      return False

    @property
    def is_anonymous(self):
        return True

    def get_id(self):
        return
```

After overriding the inherited `is_active` logic so that it returns `True`, the dashboards are embedded correctly.


### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.11

### Node version

18 or greater

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",charlymarchiaro,1,"authentication, embedded",https://github.com/apache/superset/issues/36598,2025-12-12T22:21:43Z,,negative,bug,high
3724051146,36595,Table charts reloading non-stop,closed,"### Bug description

Pull from master and run Superset. Table charts keep reloading and firing database queries.

### Screenshots/recordings

https://github.com/user-attachments/assets/4e37d6fe-36a5-44c4-8ff7-4accda0abbaf

### Superset version

master / latest-dev

### Python version

3.11.14

### Node version

v20.19.5

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [ ] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",michael-s-molina,2,viz:charts:table,https://github.com/apache/superset/issues/36595,2025-12-12T16:27:23Z,2025-12-19T21:45:37Z,negative,bug,high
3723505831,36592,dbs.impersonate_user = true does not work,open,"### Bug description

1. There is user1 with dataset1, chart1 and dashboard1. Dashboard1 based on chart1 which based on dataset1. Dataset1 points to Clickhouse table1.
2. There is user2.
3. I have enabled impersonation for user2 - e.g. I put: impersonate_user = true for user2 in dbs table of Superset DB.
4. Both user1 and user2 has database access to Clickhouse table1. Both can run query in SQL Lab and get the results: select * from table1.
5. User1 adds user2 as coowner of dataset1 in order to share dashboard1 to user2.
6. User1 opens dashboard1 and click ""Share/Copy permalink to clipboard"".
7. User2 opens permalink in browser and gets an error: DB::Exception: user2: Authentication failed: password is incorrect, or there is no user with such name.

Actually the same issue was added before but it is still unresolved: https://github.com/apache/superset/issues/17074

The route cause of the error in these rows (superset\db_engine_specs\base.py):
if impersonate_user and username is not None:
    url = url.set(username=username)

It seems in addition we should add rows like this:
    user = security_manager.find_user(username=username)
    url = url.set(password=user.password)

... But unfortunatelly, user.password contains encoded value like this:
scrypt:32768:8:1$iVy4M6mkGXr5y0AT$1b5eff974069e11d5e5d623d2d3428ed23cdfcb321167a9b7af2175b2e92c56cec16285cc9193edc9b1a1eda5638d7749c8b3fcf88fd4253ef4a41692f5d9e6f

... And I don't know how to decode it.

I checked and add this row: 
    url = url.set(password='8i^hO$0g') # it is decoded value of password
... and user can load the dashboard. But decoded password I can see in this line (superset\models\core.py):
    effective_username = self.get_effective_user(sqlalchemy_url)

here I can see decoded password in this variable: sqlalchemy_url.password
... but it happens when user loads his own dashboard.

PS: My Superset version is 3.0, but I checked last version (6.0) and this bug is still unresolved.

### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",berlicon,1,"data:connect:clickhouse, authentication",https://github.com/apache/superset/issues/36592,2025-12-12T13:52:22Z,,negative,bug,high
3722736641,36589,"Bug Report: Mismatch between Backend Permission Names (""can_list"") and Frontend Checks (""can list"") in RightMenu.tsx in 6.0.0rc4",closed,"### Bug description

I discovered a regression/bug where the ""Security"" section (List Users, List Roles) in the top-right navigation menu is hidden for authorized users.

The issue stems from a mismatch between the permission string defined in the backend ( can_list with an underscore) and the string checked in the frontend RightMenu.tsx (originally can list with a space).

- Backend : In superset/security/manager.py , the permission is referenced as can_list .
- Frontend : In superset-frontend/src/features/home/RightMenu.tsx , the code checks for findPermission('can list', ...) (space).
Since the backend API returns can_list in the user's role payload, the frontend check findPermission('can list', ...) fails, and the menu items are never rendered.
1. Frontend ( superset-frontend/src/features/home/RightMenu.tsx ):
   
   - Current behavior (Bug):
     ```
     if¬†(findPermission('can¬†list',¬†
     'UserDBModelView',¬†roles))¬†
     {¬†...¬†}
     if¬†(findPermission('can¬†list',¬†
     'RoleModelView',¬†roles))¬†
     {¬†...¬†}
     ```
   - Proposed Fix (Works locally):
     ```
     if¬†(findPermission('can_list',¬†
     'UserDBModelView',¬†roles))¬†
     {¬†...¬†}
     if¬†(findPermission('can_list',¬†
     'RoleModelView',¬†roles))¬†
     {¬†...¬†}
     ```
Environment:

### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.10

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",BearCat77,1,,https://github.com/apache/superset/issues/36589,2025-12-12T09:42:19Z,2025-12-12T10:06:31Z,negative,bug,high
3722628753,36588,deck.gl Multi-Layer Charts fail to preserve filters from Single-Layer Charts,open,"### Bug description

**Issue**

After upgrading Superset to version 5.0.0, filters applied to individual layers in a deck.gl Multiple Layers chart are not preserved when those layers are combined into a multi-layer map.

**How to reproduce the bug:**

1)  Create a deck.gl Scatterplot chart and apply a filter (e.g., Id = value). Save the chart. 
2)  Create a deck.gl Multiple Layers chart and add the previously created Scatterplot layer.

**Expected behavior:**

The Scatterplot added in step 2 should appear in the Multiple Layers chart with the original filters applied.


### Screenshots/recordings

<img width=""1626"" height=""787"" alt=""Image"" src=""https://github.com/user-attachments/assets/1169faec-1fb7-4efc-8448-150ff0fecb68"" />

<img width=""1629"" height=""748"" alt=""Image"" src=""https://github.com/user-attachments/assets/b39c93c2-e8a9-4e58-a242-aa8f3dd5c54e"" />


### Superset version

5.0.0

### Python version

I don't know

### Node version

I don't know

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",HJelinkova,1,"validation:required, viz:charts:deck.gl",https://github.com/apache/superset/issues/36588,2025-12-12T09:08:30Z,,negative,bug,medium
3721271315,36549,FAB 5.0 compatibility related bugs in 6.0.0rc4,closed,"### Bug description

## TL;DR

Superset 6.0.0rc4 has **incomplete Flask-AppBuilder 5.0.0 compatibility**. While FAB 5.0.0 is included in requirements, critical API incompatibilities prevent successful deployment.

**Verified against commit**: `6a1c30e5e7` (6.0.0rc4 release)

---

## Critical Issues

### Issue #1: Flask-SQLAlchemy 2.5.1 Incompatibility

**Error**:
```
SignallingSession.get_bind() got an unexpected keyword argument 'bind'
```

**Location**: Runtime, during database operations

**Root Cause**:
- Flask-AppBuilder 5.0.0 requires Flask-SQLAlchemy 3.x for proper SQLAlchemy 1.4 compatibility
- Superset 6.0.0rc4 pins Flask-SQLAlchemy==2.5.1 in `requirements/base.txt:137`
- This creates a `get_bind()` API incompatibility between Flask-SQLAlchemy 2.x and SQLAlchemy 1.4

**Solution**:

Update `pyproject.toml` to require Flask-SQLAlchemy 3.x:
```toml
[project]
dependencies = [
    # ... other deps ...
    ""flask-sqlalchemy>=3.0.0,<4.0"",
]
```

Then regenerate requirements:
```bash
pip-compile pyproject.toml requirements/base.in -o requirements/base.txt
pip-compile requirements/development.in -c requirements/base.txt -o requirements/development.txt
```

**Impact**: üî¥ CRITICAL - Prevents application from starting

---

### Issue #2: Removed FAB 5.0 API - `sync_role_definitions()`

**Error**:
```python
AttributeError: 'SupersetSecurityManager' object has no attribute 'sync_role_definitions'
```

**Location**: `superset/cli/main.py:85`

**Root Cause**:
Flask-AppBuilder 5.0.0 removed the `SecurityManager.sync_role_definitions()` method. The 6.0.0rc4 code still calls this removed method during initialization.

**Verification**:
```bash
$ grep -n ""sync_role_definitions"" /path/to/6.0.0rc4/superset/cli/main.py
85:    security_manager.sync_role_definitions()
```

**Solution**:

Add compatibility shim in `superset/cli/main.py`:

```python
def init() -> None:
    """"""Inits the Superset application""""""
    appbuilder.add_permissions(update_perms=True)

    # FAB 5.0.0 removed sync_role_definitions()
    # Permissions are already synced by add_permissions(update_perms=True)
    if hasattr(security_manager, 'sync_role_definitions'):
        # FAB < 5.0.0
        security_manager.sync_role_definitions()
    # FAB >= 5.0.0: No action needed, permissions already synced
```

**Alternative Solution**: Remove the call entirely, as `add_permissions(update_perms=True)` already handles role definition syncing in FAB 5.0.0.

**Impact**: üî¥ CRITICAL - Prevents `superset init` from completing

---

## Reproduction Steps

### Using Docker (Recommended)

1. Clone Superset and checkout 6.0.0rc4:
```bash
git clone https://github.com/apache/superset.git
cd superset
git checkout 6a1c30e5e7  # 6.0.0rc4
```

2. Attempt to initialize:
```bash
docker compose up superset-init
```

3. Observe failures:
   - Issue #1: `get_bind()` errors during database operations
   - Issue #2: `AttributeError` on `sync_role_definitions()`

### Using Local Installation

1. Install Superset 6.0.0rc4:
```bash
pip install apache-superset==6.0.0rc4
```

2. Initialize database:
```bash
superset db upgrade
superset init
```

3. Observe `AttributeError: 'SupersetSecurityManager' object has no attribute 'sync_role_definitions'`

---

## Environment Details

**Working Configuration** (what 6.0.0rc4 needs):
- Flask-AppBuilder: 5.0.0
- Flask-SQLAlchemy: 3.0.5+ (or any 3.x)
- SQLAlchemy: 1.4.54

**Current 6.0.0rc4 Configuration** (broken):
- Flask-AppBuilder: 5.0.0 ‚úÖ
- Flask-SQLAlchemy: 2.5.1 ‚ùå (should be 3.x)
- SQLAlchemy: 1.4.54 ‚úÖ

---

## Recommended Upstream Fixes

### Priority 1: Update Flask-SQLAlchemy Requirement

**File**: `pyproject.toml`

```diff
[project]
dependencies = [
    # ... other dependencies ...
+   ""flask-sqlalchemy>=3.0.0,<4.0"",
    # ... other dependencies ...
]
```

**File**: `requirements/base.txt` (regenerated from pyproject.toml)

```diff
- flask-sqlalchemy==2.5.1
+ flask-sqlalchemy==3.0.5  # (or latest 3.x)
```

### Priority 2: Fix sync_role_definitions() Call

**File**: `superset/cli/main.py`

**Option A** (Backward compatible):
```python
def init() -> None:
    """"""Inits the Superset application""""""
    appbuilder.add_permissions(update_perms=True)

    # Handle FAB 4.x and 5.x compatibility
    if hasattr(security_manager, 'sync_role_definitions'):
        security_manager.sync_role_definitions()
```

**Option B** (Clean, FAB 5.0+ only):
```python
def init() -> None:
    """"""Inits the Superset application""""""
    # FAB 5.0.0+ handles role definitions in add_permissions()
    appbuilder.add_permissions(update_perms=True)
```

---

## Related Issues & PRs

- **FAB 5.0 Upgrade PR**: https://github.com/apache/superset/pull/33055
- **FAB 5.0.0 Release Notes**: https://github.com/dpgaspar/Flask-AppBuilder/releases/tag/v5.0.0
- **FAB Migration Guide**: https://flask-appbuilder.readthedocs.io/en/latest/versionmigration.html#migrating-to-5-0-0
- **Flask-SQLAlchemy 3.x Changes**: https://flask-sqlalchemy.palletsprojects.com/en/3.1.x/changes/#version-3-0-0

---

## Testing Checklist

After applying fixes, verify:

- [ ] `docker compose up superset-init` completes without errors
- [ ] Database migrations run successfully
- [ ] Admin user is created
- [ ] Roles and permissions are initialized
- [ ] Example data loads (if using examples)
- [ ] Application starts and is accessible at http://localhost:8088
- [ ] Login works with created admin credentials

---

## Additional Notes

### Why Flask-SQLAlchemy 3.x is Required

FAB 5.0.0 was updated to use SQLAlchemy 1.4+ features that require Flask-SQLAlchemy 3.x for proper integration. The main issue is the `get_bind()` method signature change:

- **Flask-SQLAlchemy 2.x**: `get_bind(mapper=None, clause=None, bind=None)`
- **Flask-SQLAlchemy 3.x**: `get_bind(mapper=None, clause=None)` (removed `bind` parameter)

SQLAlchemy 1.4 calls `get_bind()` without the `bind` parameter, which Flask-SQLAlchemy 2.x doesn't support.

### Why sync_role_definitions() Was Removed

In FAB 5.0.0, the role definition syncing logic was consolidated into the `add_permissions()` method when called with `update_perms=True`. The separate `sync_role_definitions()` method became redundant and was removed.

### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",diegoscarabelli,7,change:backend,https://github.com/apache/superset/issues/36549,2025-12-11T23:08:46Z,2025-12-15T19:11:44Z,negative,bug,high
3720085772,36534,The image downloaded from the superset using the ‚ÄòDownload as image‚Äô option appears blank for the pie chart.,open,"### Bug description

Steps to Reproduce

1. Launch the superset
2. Go to Dashboards
3. Select dashboard and edit chart

4. click on more icon and Downloads

5. select ""Download as image"" for the pie chart

6. Open the downloaded image

Expected Behavior

Should display the pie chart
Actual Behavior

image is blank

### Screenshots/recordings

<img width=""976"" height=""706"" alt=""Image"" src=""https://github.com/user-attachments/assets/95dcf48b-0b98-4fb1-b7b3-37e425900bdf"" />

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [ ] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",sandeepsangoju270,2,viz:charts:export,https://github.com/apache/superset/issues/36534,2025-12-11T16:22:14Z,,negative,bug,high
3719702008,36530,(low priority) Histogram throws warning in logs in 6.0.0rc4,open,"### Bug description

When you load a dashboard with a Histogram chart, or edit one directly, this Pandas warning appears in the logs:
```
superset_app          | /app/superset/utils/pandas_postprocessing/histogram.py:57: SettingWithCopyWarning: 
superset_app          | A value is trying to be set on a copy of a slice from a DataFrame.
superset_app          | Try using .loc[row_indexer,col_indexer] = value instead
superset_app          | 
superset_app          | See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
superset_app          |   df[column] = to_numeric(df[column], errors=""coerce"")
```

Doesn't seem to be affecting anything in how the application operates, just something to clean up.

### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

I don't know

### Node version

I don't know

### Browser

Not applicable

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",sfirke,7,"good first issue, viz:charts:histogram",https://github.com/apache/superset/issues/36530,2025-12-11T14:43:38Z,,neutral,bug,low
3717793789,36500,View Query Not SHowing.,open,"### Bug description

In embedded dashboard, view query is not working.

Its coming empty.

Superset version : 5.0.0-dev

### Screenshots/recordings

<img width=""1641"" height=""878"" alt=""Image"" src=""https://github.com/user-attachments/assets/51db9cfd-53d7-4a66-acc7-2182c8d45cf3"" />

### Superset version

5.0.0

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",stockarea,1,"validation:required, embedded",https://github.com/apache/superset/issues/36500,2025-12-11T05:13:48Z,,negative,bug,high
3715020353,36492,Secrets are leaked in log /stddout,open,"### Bug description

[2025-12-10 12:30:17 +0000] [369] [INFO] Worker exiting (pid: 369)
ERROR: Cannot connect to database postgresql+psycopg2://__USER__:__PW__@psql-dev-szn-01.postgres.database:5432/superset
NOTE: Most CLI commands require a database

### Screenshots/recordings

<img width=""1956"" height=""343"" alt=""Image"" src=""https://github.com/user-attachments/assets/8c3c56a2-47cb-4d12-a63c-db9a21627fa6"" />

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",thisispr,1,infra:logging,https://github.com/apache/superset/issues/36492,2025-12-10T12:33:39Z,,negative,bug,high
3714677177,36491,Report : The text associated with a time zone differs between the selection and the displayed value.,open,"The selected zones correspond correctly to the selected value.

<img width=""714"" height=""138"" alt=""Image"" src=""https://github.com/user-attachments/assets/77a00e6f-c472-4338-8aec-a6cef2b2a1a2"" />

but for some values, the displayed text is different.

<img width=""739"" height=""92"" alt=""Image"" src=""https://github.com/user-attachments/assets/b7e78651-f979-4177-bb39-e0431ae04803"" />

",xavier-GitHub76,1,global:timezone,https://github.com/apache/superset/issues/36491,2025-12-10T10:53:38Z,,neutral,bug,medium
3711635606,36485,Permissions denied while fetching chart info:Forbidden,closed,"### Bug description

Hi!

I'm using **apache-superset==5.0.0** with Postgres as well. Using the user ""admin"", I got several error on the web UI.
The log shows:
`2025-12-09 17:00:30,689:INFO:werkzeug:100.76.210.16 - - [09/Dec/2025 17:00:30] ""GET /api/v1/log/recent_activity/?q=(distinct:!f,page_size:24) HTTP/1.1"" 403 - 2025-12-09 17:00:30,689:INFO:werkzeug:100.76.210.16 - - [09/Dec/2025 17:00:30] ""GET /api/v1/dashboard/?q=(filters:!((col:owners,opr:rel_m_m,value:'1')),order_column:changed_on_delta_humanized,order_direction:desc,page:0,page_size:5) HTTP/1.1"" 403 - 2025-12-09 17:00:30,814:INFO:werkzeug:100.76.210.16 - - [09/Dec/2025 17:00:30] ""GET /api/v1/saved_query/?q=(filters:!((col:created_by,opr:rel_o_m,value:'1')),order_column:changed_on_delta_humanized,order_direction:desc,page:0,page_size:5) HTTP/1.1"" 403 - 2025-12-09 17:00:30,816:INFO:werkzeug:100.76.210.16 - - [09/Dec/2025 17:00:30] ""GET /api/v1/chart/?q=(filters:!((col:owners,opr:rel_m_m,value:'1')),order_column:changed_on_delta_humanized,order_direction:desc,page:0,page_size:5) HTTP/1.1"" 403 - 2025-12-09 17:00:30,934:INFO:werkzeug:100.76.210.16 - - [09/Dec/2025 17:00:30] ""GET /api/v1/saved_query/_info?q=(keys:!(permissions)) HTTP/1.1"" 403 - `

Why do I got this while I'm admin? I didn't compare the postgres db and sqlite but is postgres deprecated if database upgrade is not working as mention by @lboross-ia in #24469

Also, I didn't find any documentation about metadata management.
Does someone find it?

Anything help would be appreciate :)
Thanks!

### Screenshots/recordings

<img width=""764"" height=""488"" alt=""Image"" src=""https://github.com/user-attachments/assets/b0cee515-8b3d-4d13-8ed1-754e061b4ce1"" />

### Superset version

5.0.0

### Python version

3.11

### Node version

I don't know

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",xueyun0512,2,"authentication, review:checkpoint",https://github.com/apache/superset/issues/36485,2025-12-09T16:11:55Z,2025-12-09T18:15:59Z,negative,bug,medium
3710977624,36484,Drill feature and permissions,open,"### Bug description

Hi,

**With the drill feature on dashboards, without permission on the individual datasets of the charts, we get to see the drill data but also get the error ""There was an error loading the dataset metadata"".**

Superset version is 5.0.0, not sure wether or not that behavior was the same in previous versions.

We do grant access to dashboards via the dashboard properties with roles.
The role we use have ""can drill on dashboards"" and ""can samples on datasource"" permissions. It is sufficient to get access to the data in the drill but there still is a ""There was an error loading the dataset metadata"" error message instead of the dataset metadata. 

The only way to get rid of this error we could find is to grand access to the dataset of the chart we are drilling on to the role. But 
- then the access management via dashboard properties does not make sense anymore as we have to individually manage access to datasets on top for the drill feature
- it seems weird to access the data itself without the permission on the dataset but not the metadata if the intention is actually to require individual dataset access for the drill feature

Thanks!



### Screenshots/recordings

<img width=""1168"" height=""198"" alt=""Image"" src=""https://github.com/user-attachments/assets/ac0572bf-d562-4a69-8e52-6fd6e29c2f27"" />

### Superset version

5.0.0

### Python version

Not applicable

### Node version

Not applicable

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",Flvn,2,"authentication:access-control, dashboard:drill-down",https://github.com/apache/superset/issues/36484,2025-12-09T13:37:55Z,,negative,bug,medium
3710630393,36482,Not able to run any SQL query on SQL lab,closed,"### Bug description

I have created a connection to StarRocks in Apache Superset using the StarRocks dialect. However, when I try to run an SQL query (even a simple SELECT) in Superset‚Äôs SQL Lab, I get an ‚Äúauthentication required‚Äù error ‚Äî indicating an issue with the StarRocks database connection. Database connection is already successfully connected and able to see tables created in starrocks but not able to run any query on it.
Can anyone please help here?

<img width=""1188"" height=""344"" alt=""Image"" src=""https://github.com/user-attachments/assets/cf1519c6-0476-44e5-aca1-10b5949c5e48"" />

<img width=""673"" height=""164"" alt=""Image"" src=""https://github.com/user-attachments/assets/906ce6df-8209-4d9e-bcbe-71a318549d47"" />


### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",ABDevops-test,12,"sqllab, data:connect:starrocks",https://github.com/apache/superset/issues/36482,2025-12-09T12:20:11Z,2025-12-17T17:05:03Z,negative,bug,high
3710574381,36480,"When you click logout in the settings section, you get an error notification",open,"### Bug description

When you click logout in the settings section, you get an error notification ""invalid username or password"" but one is still successfully logged out.

### Screenshots/recordings

<img width=""1192"" height=""856"" alt=""Image"" src=""https://github.com/user-attachments/assets/9edf7d6f-ce12-4472-9a38-8fd38764bdec"" />

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [ ] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",LevisNgigi,0,authentication,https://github.com/apache/superset/issues/36480,2025-12-09T12:04:39Z,,negative,bug,medium
3709863467,36478,Deck.gl multiple layers chart - cannot control layer rendering order,open,"### Bug description

**Issue:**

In a deck.gl chart with multiple layers, the rendering order of layers cannot be controlled and appears inconsistent or random.

**How to reproduce the bug:**

1)	Create a deck.gl Scatterplot chart and assign a single color to all points. Save the chart as Name_1.
2)	Duplicate the above Scatterplot chart, change the color for the same points, and save it as Name_2.
3)	Create a new deck.gl Multiple Layers chart.
4)	Add the previously created Scatterplot charts (Name_1 and Name_2) as layers.
5)	Attempt to change the order of the charts within the Multiple Layers chart.

**Expected behavior:**

The first selected Scatterplot should render at the bottom, and the last selected Scatterplot should render on top. 
This ordering should work consistently for two or more layers. 



### Screenshots/recordings

<img width=""1671"" height=""707"" alt=""Image"" src=""https://github.com/user-attachments/assets/e33cf183-d33a-45d4-a953-ccdfb612cc93"" />

<img width=""1656"" height=""715"" alt=""Image"" src=""https://github.com/user-attachments/assets/d038008c-ae58-4838-b9a5-daccad79c829"" />

### Superset version

4.1.3

### Python version

I don't know

### Node version

I don't know

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",HJelinkova,2,viz:charts:deck.gl,https://github.com/apache/superset/issues/36478,2025-12-09T08:51:38Z,,negative,bug,medium
3707808618,36459,[6.0.0rc4] i18n Fails in Embedded Dashboards Due to /language_pack/<lang>/ Auth Error,open,"### Bug description

I use the following code to set the correct locale:

```
def set_locale_from_url_param():
    from flask import session, request
    locale_param = request.args.get('lang')
    if locale_param:
        supported_locales = ['de', 'fr']
        if locale_param in supported_locales:
            session[""locale""] = locale_param

FLASK_APP_MUTATOR = lambda app: app.before_request(set_locale_from_url_param)
````

That works fine, however, the call to `language_pack/<lang>/` is unauthorized because the guest token is not set yet.

### Screenshots/recordings

_No response_

### Superset version

6.0.0rc4

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",gerbermichi,4,"i18n, embedded",https://github.com/apache/superset/issues/36459,2025-12-08T19:57:21Z,,negative,bug,high
3703644216,36448,Alerts & Reports fail on ARM64: Selenium cannot obtain Chrome/Firefox driver (‚ÄúUnsupported platform/architecture linux/aarch64‚Äù),closed,"### Bug description

When running Apache Superset on ARM64 (AWS Graviton / linux/aarch64), all Alerts & Reports that require screenshot generation fail with the following Selenium error:
```
selenium.common.exceptions.WebDriverException: Message: Unsupported platform/architecture combination: linux/aarch64
```
Superset attempts to use Selenium Manager to automatically download a Chrome or Firefox WebDriver. Selenium Manager does not ship drivers for ARM64, which results in:
	‚Ä¢	Unable to obtain driver for chrome
	‚Ä¢	Unable to obtain driver for firefox
	‚Ä¢	Reports failing with ReportScheduleScreenshotFailedError

This makes Alerts & Reports completely non-functional on ARM environments, even when Chromium + Chromedriver are installed manually inside the container.
I can just sent it to a Slack channel as a CSV , not PNG not no other.


Environment
	‚Ä¢	Architecture: ARM64 (aarch64) ‚Äî AWS Graviton worker nodes
	‚Ä¢	Superset version: 3.x / latest Docker image
	‚Ä¢	Python: 3.10
	‚Ä¢	Selenium: bundled with official Superset image
	‚Ä¢	Chromium + chromedriver manually installed in /usr/bin
	‚Ä¢	Reports & Alerts enabled and Celery working
	‚Ä¢	Error occurs in both superset-worker and superset-celerybeat

### Screenshots/recordings

```
[2025-12-07 15:53:00,352: WARNING/ForkPoolWorker-1] /app/.venv/lib/python3.10/site-packages/snowflake/sqlalchemy/base.py:1068: SAWarning: The GenericFunction 'flatten' is already registered and is going to be overridden.
  functions.register_function(""flatten"", flatten)

[2025-12-07 15:53:00,416: ERROR/ForkPoolWorker-1] A downstream exception occurred while generating a report: 3f764eef-245a-41e8-ae06-544bbaededd0. Failed taking a screenshot Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
Traceback (most recent call last):
  File ""/app/.venv/lib/python3.10/site-packages/selenium/webdriver/common/driver_finder.py"", line 67, in _binary_paths
    output = SeleniumManager().binary_paths(self._to_args())
  File ""/app/.venv/lib/python3.10/site-packages/selenium/webdriver/common/selenium_manager.py"", line 47, in binary_paths
    args = [str(self._get_binary())] + args
  File ""/app/.venv/lib/python3.10/site-packages/selenium/webdriver/common/selenium_manager.py"", line 94, in _get_binary
    raise WebDriverException(f""Unsupported platform/architecture combination: {sys.platform}/{arch}"")
selenium.common.exceptions.WebDriverException: Message: Unsupported platform/architecture combination: linux/aarch64


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/app/superset/commands/report/execute.py"", line 375, in _get_screenshots
    if imge := screenshot.get_screenshot(user=user):
  File ""/app/superset/utils/screenshots.py"", line 179, in get_screenshot
    self.screenshot = driver.get_screenshot(self.url, self.element, user)
  File ""/app/superset/utils/webdriver.py"", line 463, in get_screenshot
    driver = self.auth(user)
  File ""/app/superset/utils/webdriver.py"", line 387, in auth
    driver = self.create()
  File ""/app/superset/utils/webdriver.py"", line 384, in create
    return driver_class(**kwargs)
  File ""/app/.venv/lib/python3.10/site-packages/selenium/webdriver/chrome/webdriver.py"", line 45, in __init__
    super().__init__(
  File ""/app/.venv/lib/python3.10/site-packages/selenium/webdriver/chromium/webdriver.py"", line 51, in __init__
    if finder.get_browser_path():
  File ""/app/.venv/lib/python3.10/site-packages/selenium/webdriver/common/driver_finder.py"", line 47, in get_browser_path
    return self._binary_paths()[""browser_path""]
  File ""/app/.venv/lib/python3.10/site-packages/selenium/webdriver/common/driver_finder.py"", line 78, in _binary_paths
    raise NoSuchDriverException(msg) from err
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/app/superset/tasks/scheduler.py"", line 125, in execute
    ).run()
  File ""/app/superset/utils/decorators.py"", line 267, in wrapped
    return on_error(ex)
  File ""/app/superset/utils/decorators.py"", line 232, in on_error
    raise ex
  File ""/app/superset/utils/decorators.py"", line 260, in wrapped
    result = func(*args, **kwargs)
  File ""/app/superset/commands/report/execute.py"", line 956, in run
    ).run()
  File ""/app/superset/utils/decorators.py"", line 256, in wrapped
    return func(*args, **kwargs)
  File ""/app/superset/commands/report/execute.py"", line 917, in run
    ).next()
  File ""/app/superset/commands/report/execute.py"", line 746, in next
    self.send()
  File ""/app/superset/commands/report/execute.py"", line 644, in send
    notification_content = self._get_notification_content()
  File ""/app/superset/commands/report/execute.py"", line 529, in _get_notification_content
    pdf_data = self._get_pdf()
  File ""/app/superset/commands/report/execute.py"", line 393, in _get_pdf
    screenshots = self._get_screenshots()
  File ""/app/superset/commands/report/execute.py"", line 381, in _get_screenshots
    raise ReportScheduleScreenshotFailedError(
superset.commands.report.exceptions.ReportScheduleScreenshotFailedError: Failed taking a screenshot Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
```

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",shalom-t,1,alert-reports,https://github.com/apache/superset/issues/36448,2025-12-07T15:57:43Z,2025-12-08T16:53:04Z,negative,bug,high
3698297976,36439,[6.0.0rc3] Unable to send CSV charts in reports,open,"### Bug description

We are currently using `6.0.0rc3` and have noticed that CSV reports are sending only the headers. I am attaching two images. The first is proof that the Dataset does indeed have data and I can access it. The second is the empty report, first as a CSV which just sends the headers and the same report sent as an image that shows that the chart does not contain any data.

There are no RLS filters on the charts and I am using an admin account to send the reports

We've tested a bunch of scenarios and are seeing the same result. The only exception so far has been when I created a tiny dataset based on an SQL Lab query that worked. Steps we've taken so far in testing:
1. Change the Chart to a different table Chart
2. Recreate the Dataset with a different owner
3. Change the owner of the report
4. Create a new Chart based on the new Dataset
5. Change the delivery from email to Slack
6. Change the message type from CSV to image (see below)

This is not isolated to a single chart, we have tested with multiple charts. Manually downloading the data as a CSV from the Chart's edit menu works correctly

Were there any changes to permissions in this release that might apply a filter? Other chart types seem unaffected.

There is nothing in the logs that suggest an error while generating the report

### Screenshots/recordings

<img width=""2613"" height=""674"" alt=""Image"" src=""https://github.com/user-attachments/assets/d2d731d4-498f-4c4d-ae82-b6c69f871a1a"" />

<img width=""506"" height=""505"" alt=""Image"" src=""https://github.com/user-attachments/assets/e4f6d671-0a5b-4a41-b7d5-fdcf2934c11b"" />

### Superset version

master / latest-dev

### Python version

3.11

### Node version

I don't know

### Browser

Not applicable

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",SkinnyPigeon,5,"requires:more-info, alert-reports",https://github.com/apache/superset/issues/36439,2025-12-05T10:00:04Z,,negative,bug,high
3693354767,36419,The header merge column width of the pivot plugin cannot cover the entire table,closed,"### Bug description

In the pivot viz plugin with a particularly large number of columns, the width of the header merged columns cannot cover the entire table

### Screenshots/recordings

<img width=""1429"" height=""514"" alt=""Image"" src=""https://github.com/user-attachments/assets/f3e7af2f-9978-4d2a-af0f-fd2345d73379"" />

### Superset version

master / latest-dev

### Python version

3.9

### Node version

18 or greater

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",CoderSxy,2,"#bug:cosmetic, viz:charts:pivot",https://github.com/apache/superset/issues/36419,2025-12-04T07:49:01Z,2025-12-04T11:10:46Z,negative,bug,medium
3692348600,36414,Default values.yaml for helm chart does not work (image pull errors),open,"### Bug description

1. Download `values.yaml` from https://github.com/apache/superset/blob/master/helm/superset/values.yaml
2. Run ` helm upgrade --install --values values.yaml superset superset/superset` as [described](https://superset.apache.org/docs/installation/installation-methods#kubernetes-k8s) 

Expected: default installation works
Actual: image pull errors for redis and postgres
```
superset-6cfd5b6684-k9699          0/1     Init:0/1           16 (5m9s ago)    18h
superset-init-db-c7bch             0/1     Init:Error         0                3m28s
superset-init-db-czrtf             0/1     Init:0/1           0                96s
superset-init-db-pt2f6             0/1     Init:Error         0                5m20s
superset-postgresql-0              0/1     ImagePullBackOff   0                30m
superset-redis-master-0            0/1     ImagePullBackOff   0                30m
superset-worker-78c4d4fbd6-zbdg8   0/1     Init:0/1           16 (5m19s ago)   18h
``` 

```
kubectl describe pod superset-redis-master-0 | grep -i image
    Image:         docker.io/bitnami/redis:7.0.10-debian-11-r4
    Image ID:
      Reason:       ImagePullBackOff
  Normal   Pulling    31m (x4 over 32m)    kubelet            Pulling image ""docker.io/bitnami/redis:7.0.10-debian-11-r4""
  Warning  Failed     31m (x4 over 32m)    kubelet            Failed to pull image ""docker.io/bitnami/redis:7.0.10-debian-11-r4"": rpc error: code = NotFound desc = failed to pull and unpack image ""docker.io/bitnami/redis:7.0.10-debian-11-r4"": failed to resolve reference ""docker.io/bitnami/redis:7.0.10-debian-11-r4"": docker.io/bitnami/redis:7.0.10-debian-11-r4: not found
  Warning  Failed     31m (x4 over 32m)    kubelet            Error: ErrImagePull
  Warning  Failed     30m (x6 over 32m)    kubelet            Error: ImagePullBackOff
  Normal   BackOff    19s (x152 over 32m)  kubelet            Back-off pulling image ""docker.io/bitnami/
```

```
 kubectl describe pod superset-postgresql-0 | grep -i image
    Image:           docker.io/bitnami/postgresql:14.17.0-debian-12-r3
    Image ID:
      Reason:        ImagePullBackOff
  Normal   Pulling    32m (x4 over 34m)     kubelet            Pulling image ""docker.io/bitnami/postgresql:14.17.0-debian-12-r3""
  Warning  Failed     32m (x4 over 34m)     kubelet            Failed to pull image ""docker.io/bitnami/postgresql:14.17.0-debian-12-r3"": rpc error: code = NotFound desc = failed to pull and unpack image ""docker.io/bitnami/postgresql:14.17.0-debian-12-r3"": failed to resolve reference ""docker.io/bitnami/postgresql:14.17.0-debian-12-r3"": docker.io/bitnami/postgresql:14.17.0-debian-12-r3: not found
  Warning  Failed     32m (x4 over 34m)     kubelet            Error: ErrImagePull
  Warning  Failed     32m (x6 over 34m)     kubelet            Error: ImagePullBackOff
  Normal   BackOff    106s (x151 over 34m)  kubelet            Back-off pulling image ""docker.io/bitnami/postgresql:14.17.0-debian-12-r3""
````


### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [ ] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",dmitrynovik,4,deploy:helm,https://github.com/apache/superset/issues/36414,2025-12-04T00:17:37Z,,negative,bug,high
3691617216,36412,[SIP] Proposal for having an announcement banner,open,"*Please make sure you are familiar with the SIP process documented*
[here](https://github.com/apache/superset/issues/5602). The SIP will be numbered by a committer upon acceptance.

## [SIP] Proposal for having an announcement banner

### Motivation

We wanted to tell users about announcements of varying severity.
For example: when GBQ goes down or something, we could have a banner letting them know or even when theres maintenance or an upgrade for expected downtime.

### Proposed Change

Theres going to be a button in settings bar that only admins should be able to see.
There is also going to be a modal that pops up that allows the admins to set whatever message they want.

<img width=""191"" height=""703"" alt=""Image"" src=""https://github.com/user-attachments/assets/16c98ad6-131a-4f18-9d61-0d9da86a13a7"" />

<img width=""540"" height=""593"" alt=""Image"" src=""https://github.com/user-attachments/assets/a11306ef-c214-44b0-a9dd-ac81922f5a7d"" />

<img width=""2520"" height=""105"" alt=""Image"" src=""https://github.com/user-attachments/assets/3241247b-7b95-4613-bc58-9c41e7a0f429"" />

<img width=""2506"" height=""297"" alt=""Image"" src=""https://github.com/user-attachments/assets/691f87e5-14dc-4482-b1ee-eeb74924eefe"" />

<img width=""2498"" height=""437"" alt=""Image"" src=""https://github.com/user-attachments/assets/5f75f855-f713-4e74-9d80-618326eaf954"" />

### New or Changed Public Interfaces

There is going to be a new announcement model requiring a DB migration, an announcement API and some frontend modals and buttons to make this happen as noted in the screenshots.

### Migration Plan and Compatibility

Migration needs to happen to get the announcement data in there
",ethan-l-geotab,3,"sip, design:proposal",https://github.com/apache/superset/issues/36412,2025-12-03T19:32:36Z,,neutral,feature_request,medium
3690065047,36407,Collapse function in sqllab,open,"

In Superset 5.0.0, tooltips in SQLLab disappeared, as did the ability to collapse large queries. This works on the same image with different environments and configurations. Could you tell me what settings can disable this in version 5? Thank you!",crazychaz,6,sqllab:design,https://github.com/apache/superset/issues/36407,2025-12-03T12:37:03Z,,neutral,question,medium
3689822615,36406,[6.0.0rc3] Same color being picked twice in a chart when dashboard doesn't have a map_label_colors,open,"### Bug description

Bug is that in a dashboard with more than 1 chart, the same color can be picked twice for a given chart. To reproduce, the dashboard needs to have an empty map_label_colors or an incomplete map_label_colors.

To reproduce:
1. Import the given superset dashboard [twice-same-color-bug.zip](https://github.com/user-attachments/files/23904698/twice-same-color-bug.zip)
2. Make sure the imported dashboard doesn't have a map_label_colors by calling the api `/api/v1/dashboard/{pk}` and check the field `json_metadata`
3. Go to the dashboard ""Twice same color bug""
4. The 2nd charts ""Call of duty Sales"" is displaying the light blue color 2 times for ""PC"" and ""Playstation"" KO
5. If the bug doesn't appear refresh the page several times

To note: 
 - This happen regardless of the type of charts used
 - This doesn't happen when you edit the dashboard first because the field map_label_colors is being filled while editing.
 - When filling the map_label_colors by editing the dashboard, if the same color is picked twice, then the map_label_color will also be filled with twice the same color.
 - Relying on fixing this bug by having a map_label_colors with all the possible values is not an optimal solution because it can be tricky to have the full list of labels for all charts and this break the theme system where the first colors are more likely to be used in the dashboard.
 - To remove the map_label_colors you can call the api `/api/v1/dashboard/{pk}/colors` with the payload `{""map_label_colors"": {}}`
 - I reproduced it in superset 6.0.0rc3 and superset 5.0.0

### Screenshots/recordings

We are using the superset theme which contains the following colors:
 1. light blue
 2. dark blue
 3. green
For every chart the color picking logic is the same, the 1st label have the 1st color, 2nd label 2nd colors... If a label already have a picked color for the current dashboard then this color will be used.

In this example with have 2 charts. So 1st chart have labels: ""Playstation"", ""Xbox"" and 2nd chart have ""PC"", ""Playstation"", ""Xbox""

On the first load:
 - The 1st chart got loaded first so light blue is assigned to ""Playstation"" and dark blue to ""Xbox""
 - Then the 2nd chart is loaded, so light blue is assigned to ""PC"" and then the others labels already have a color in this dashboard so light blue goes to ""Playstation"" and dark blue to ""Xbox""
 - KO

On the 2nd load:
 - The 2nd chart got loaded first so light blue is assigned to ""PC"" and dark blue to ""Playstation"" and green to ""Xbox""
 - Then 1st chart is loaded, all labels have assigned colors. So the colors are reused and dark blue goes to ""Playstation"" and green to ""Xbox""
 - OK

On the 3rd load:
 - We are in the same case as the 1st load

Full video of the bug:
https://github.com/user-attachments/assets/a0c637e9-d633-4c43-9302-baf724832d99

Observed behaviour (1st load):
<img width=""1506"" height=""929"" alt=""Image"" src=""https://github.com/user-attachments/assets/2c0c7e9c-f497-41a8-8be0-d96d3889b0aa"" />

Expected behaviour (2nd load):
<img width=""1506"" height=""929"" alt=""Image"" src=""https://github.com/user-attachments/assets/6ce53754-dc20-4b52-8c1a-3d226c904bb9"" />

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

The STR are using the superset theme with the example datasource.
Before exporting the dashboard, the map_label_colors of the dashboard was emptied by calling the api.

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",ablanchard,5,"dashboard:colors, ü¶æ ai-candidate",https://github.com/apache/superset/issues/36406,2025-12-03T11:26:44Z,,negative,bug,high
3689094314,36403,Active menu item not highlighted when using Russian language,open,"### Bug description

Menu's active tab highlighting mechanism fails when Superset's interface language is set to Russian locale. This occurs because the active tab detection logic compares hardcoded English strings against localized menu item keys.

**Note:** The highlighting is currently broken for Russian locale, but this represents a systemic localization issue that affects all non-English interfaces. Any language where menu item translations don't exactly match the hardcoded English comparison strings will experience the same problem.

### Steps to reproduce
1. In config.py set the LANGUAGES variables:
```py
LANGUAGES = {
    ""en"": {""flag"": ""us"", ""name"": ""English""},
    ""ru"": {""flag"": ""ru"", ""name"": ""Russian""},
}
```
2. Open the ""Dashboards"" tab
3. Observe that the ""Dashboards"" tab in the header is highlighted as active
4. Switch the UI language to Russian language 
5. Open the ""Dashboards"" tab
6. Observe that the ""Dashboards"" tab in the header is NOT highlighted as active

### Screenshots/recordings

English (working):
<img width=""956"" height=""432"" alt=""Image"" src=""https://github.com/user-attachments/assets/92d66794-521c-43dc-a576-93279d03136f"" />

Russian (broken):
<img width=""1917"" height=""876"" alt=""Image"" src=""https://github.com/user-attachments/assets/ea08d55c-af74-4b0b-9500-a4b86a1dddc3"" />




### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",innovark37,3,i18n:russian,https://github.com/apache/superset/issues/36403,2025-12-03T08:37:34Z,,negative,bug,medium
3688854077,36401,"[Bug] Regression in 5.0.0: TypeError ""Cannot mix BigInt and other types"" when rendering charts with large integers",open,"### Bug description

**Describe the bug**
When visualizing data that contains large integer values, the frontend throws a `TypeError: Cannot mix BigInt and other types.`

It seems that Superset correctly identifies these large numbers as BigInt in the data fetching layer, but the visualization library (ECharts) or the transformation layer attempts to mix these BigInt values with standard Number types during rendering, causing the crash.

**This issue was NOT present in Superset version 4.1.4 (and earlier). It appears to be a regression introduced in version 5.0.0.**


**Reproduction Steps**

1.  Go to **SQL Lab**.
2.  Select a database (e.g., PostgreSQL).
3.  Run the following query to generate virtual data with large integers (approx. 9\~10 quadrillion):
    ```sql
    SELECT '2025-01-01'::date date_key, 10402176025875170 a, 9182221549972519 b
    UNION ALL
    SELECT '2025-01-02'::date date_key, 290783677762650 a, 9915708291358753 b
    ```
4.  Click **Create Chart** and select **Line Chart** (or Bar Chart).
5.  Set **X-axis** to `date_key`.
6.  Set **Metrics** to `sum(a)` and `sum(b)`.
7.  With these settings, the generated query looks like this:
    ```sql
    SELECT
        date_key AS date_key,
        sum(a) AS ""sum(a)"",
        sum(b) AS ""sum(b)""
    FROM (
        SELECT '2025-01-01'::date date_key, 10402176025875170 a, 9182221549972519 b
        UNION ALL
        SELECT '2025-01-02'::date date_key, 290783677762650 a, 9915708291358753 b
    ) AS virtual_table
    GROUP BY date_key
    ORDER BY ""sum(a)"" DESC
    LIMIT 1000;
    ```
8.  Click **Update Chart**.
9.  Observe the error.

**Expected behavior**
The chart should render correctly, similar to how it behaved in version 4.1.4. The frontend should ideally cast BigInt to Number automatically (even with a precision loss warning) or handle large integers gracefully within the visualization library, rather than crashing the entire component.

### Screenshots/recordings


<img width=""1910"" height=""798"" alt=""Image"" src=""https://github.com/user-attachments/assets/2591d27d-9ff6-40ba-9c59-39ce2c4fc955"" />

<img width=""1909"" height=""912"" alt=""Image"" src=""https://github.com/user-attachments/assets/7419de76-6bf2-46f7-b7af-166b4ca1ebdf"" />


### Superset version

5.0.0

### Python version

3.10

### Node version

I don't know

### Browser

Chrome

### Additional context

This issue was NOT present in Superset version 4.1.4 (and earlier). It appears to be a regression introduced in version 5.0.0.


### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",jongkookson,1,"validation:required, #bug:regression, viz:charts:line",https://github.com/apache/superset/issues/36401,2025-12-03T07:17:49Z,,negative,bug,high
3687752180,36385,Large chart data doesn't return a helpful error message,open,"### Bug description

Theres a interesting interaction where a chart which requests a lot of data for the form_data won't display correctly on chrome. It works fine on Firefox though.


The request is about 950 mbs? I'm not sure what the cutoff limit is. I think if it's probably a browser limitation.



### Screenshots/recordings

The endpoint returns 200, but the frontend displays this:

<img width=""1907"" height=""1039"" alt=""Image"" src=""https://github.com/user-attachments/assets/f8b20a0d-eafb-4db0-9cd3-f362da9f4050"" />

On Firefox it displays correctly:

<img width=""1874"" height=""1038"" alt=""Image"" src=""https://github.com/user-attachments/assets/608972b8-46d4-409a-96b7-4f43e466ec8c"" />

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [ ] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",ethan-l-geotab,6,browser:chrome,https://github.com/apache/superset/issues/36385,2025-12-02T22:27:28Z,,negative,bug,medium
3686275370,36381,Error while importing dashboard,closed,"### Bug description

Hi team, Getting the error while importing dashboard from one superset( 3.1.1) to 4.1.4 versions superset
Please find this error

![Image](https://github.com/user-attachments/assets/f49630d7-659e-44ea-8060-3e9456de515f)

### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [ ] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",NarendraKotapati,2,"dashboard:error, dashboard:import",https://github.com/apache/superset/issues/36381,2025-12-02T15:07:21Z,2025-12-03T18:12:00Z,negative,bug,high
3686033528,36379,üêõ [Deprecation] snowflake-sqlalchemy entered maintenance mode (May 2025) - Migration Strategy,closed,"### Bug description

üêõ As of May 8, 2025, the snowflake-sqlalchemy library has officially transitioned to maintenance mode and has ceased active development. According to the official documentation, support is now limited strictly to critical bugs and security vulnerabilities.

Snowflake currently recommends using the **snowflake-connector-python** directly or transitioning to supported alternatives where applicable.

Given Superset's reliance on SQLAlchemy dialects, this raises a concern regarding long-term support, feature compatibility, and security for Snowflake connections within Superset.

### Sources:

- Superset Documentation: [Connecting to Databases - Snowflake ](https://superset.apache.org/docs/configuration/databases#snowflake)
- Superset Code: [Superset PyProject Toml](https://github.com/apache/superset/blob/51798edb23875fdca3f191094b1844c3d0412d9a/pyproject.toml#L179C15-L179C36)
- PyPI Project Status: [snowflake-sqlalchemy](https://pypi.org/project/snowflake-sqlalchemy/)
- Snowflake Recommendation: [Snowflake Python Connector Documentation](https://docs.snowflake.com/en/developer-guide/python-connector/python-connector-install)

### Reproduction Steps

- Review the current requirements or setup.py in the Superset repository.
- Observe the dependency on snowflake-sqlalchemy.
- Consult the official snowflake-sqlalchemy PyPI page or documentation regarding its maintenance status.

### Expected Behavior

Superset should have a roadmap or strategy to address this deprecation, whether by:

- Updating the Snowflake database engine spec to align with Snowflake's new recommendations.
- Identifying a community-maintained fork or alternative SQLAlchemy dialect for Snowflake.

### Screenshots/recordings

<img width=""1350"" height=""779"" alt=""Image"" src=""https://github.com/user-attachments/assets/c4a3c247-6c6f-4bec-a27b-f195e2528a16"" />

<img width=""1588"" height=""502"" alt=""Image"" src=""https://github.com/user-attachments/assets/e8f50208-6a5b-4f6a-89d6-efaf1b708de0"" />

### Superset version

master / latest-dev

### Python version

3.11

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",marianysilva,2,data:connect:snowflake,https://github.com/apache/superset/issues/36379,2025-12-02T14:10:29Z,2025-12-12T18:15:32Z,negative,bug,high
3685215165,36377,Embedded dashboard shows chart action menu (3-dots). How to hide it in read-only mode?,open,"### Bug description

Hi,
I am embedding a Superset dashboard using a permalink inside an iframe:

<iframe
  src=""https://<your-domain>/superset/dashboard/p/<permalink>/?standalone=1""
  width=""100%"" height=""900"">
</iframe>


The dashboard loads correctly, but inside the embedded view, every chart still shows the 3-dots action menu (Edit Chart, View Query, Share, Export, etc.).

I want the embedded dashboard to be fully read-only, so that users cannot see any edit or query options.

What I tried:

> Using standalone=1 / 2 / 3
> Using permalink URL and normal dashboard URL
> Setting allowed domains in Embed settings
> Testing in incognito (not logged in)

Still the chart action menu appears.

Request;
What is the correct way to hide the chart action menu (3-dots) when embedding a Superset dashboard in an iframe?
Is iframe embed supported for read-only mode, or should I use the Embedded SDK + guest token?

Thanks.

<img width=""1274"" height=""307"" alt=""Image"" src=""https://github.com/user-attachments/assets/20a3d99a-ab61-46ad-a39e-2a13c527663f"" />

### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [ ] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",damodhar-admin,6,embedded,https://github.com/apache/superset/issues/36377,2025-12-02T10:39:07Z,,neutral,bug,medium
3684974904,36374,chinese characters appear garbled when export to CSV,open,"### Bug description

1,click the download button with the chart,
2,select ""export to csv""

### Screenshots/recordings

<img width=""692"" height=""258"" alt=""Image"" src=""https://github.com/user-attachments/assets/6b9c8e7b-4462-4a6b-ba66-ddb0046650d6"" />




### Superset version

master / latest-dev

### Python version

3.10

### Node version

16

### Browser

Chrome

### Additional context

superset version: 6.0.0rc3

i have reviewed the following related issues:
fix(csv): manually encode CSV output to support utf-8-sig #1
fix: Download to CSV shows a special Chinese characters #29506

i have applied the following setting:
in superset_config.py
`CSV_EXPORT = {'encoding': 'utf-8-sig'}`

however,the issue(chinese character garbling) persists. the documentation suggests a solution:downgrading Werkzeug to version 2.3.8. Is this the only available solution?""

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",lwqhp,1,"validation:required, data:csv",https://github.com/apache/superset/issues/36374,2025-12-02T09:37:04Z,,negative,bug,high
3683604757,36370,table header and content misalignment,open,"### Bug description

When the user scrolls the table horizontally to its rightmost extent, a visual discrepancy appears where the column headers fail to align correctly with the corresponding data cells in the table body.




### Screenshots/recordings

<img width=""1372"" height=""1271"" alt=""Image"" src=""https://github.com/user-attachments/assets/b9173a71-fca5-4e8d-bb73-15dbbdc6a770"" />



### Superset version

master / latest-dev

### Python version

3.10

### Node version

16

### Browser

Chrome

### Additional context

superset version: 6.0.0rc2

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",lwqhp,4,"#bug:cosmetic, viz:charts:table",https://github.com/apache/superset/issues/36370,2025-12-02T01:43:09Z,,negative,bug,medium
3680773922,36357,PublishedLabel overlaps text on dashboard card when using non-English languages,open,"## Screenshot
#### English (working correctly):
<img width=""1896"" height=""377"" alt=""Image"" src=""https://github.com/user-attachments/assets/559868bb-5943-4232-b856-cc903c666729"" />

#### Spanish (bug present):
<img width=""1897"" height=""382"" alt=""Image"" src=""https://github.com/user-attachments/assets/39095dfa-71d2-49ad-a969-bba125757e92"" />

#### German (bug present):
<img width=""1898"" height=""387"" alt=""Image"" src=""https://github.com/user-attachments/assets/da3f63fd-2c27-4307-8591-b35ee0322205"" />

## Description

Issue occurs on the Welcome page when using non-English languages. The status labels (""Published""/""Draft"") do not have adequate spacing or responsive behavior to accommodate longer translations in other languages. This causes the label to visually overlap the ""Modified X ago"" timestamp, making both text elements difficult or impossible to read.

#### Current Behavior
- English: Layout works correctly - ""Modified 20 minutes ago"" and ""Published"" label appear side by side without overlap
- Spanish/German/Russian/other languages: Translated labels are often longer and overlap with the timestamp text

#### Expected Behavior
- Text elements should never overlap regardless of language
- Layout should be responsive and accommodate longer translations
- Proper spacing or truncation should be applied to prevent overlap
",innovark37,1,"#bug:cosmetic, dashboard:design",https://github.com/apache/superset/issues/36357,2025-12-01T12:27:53Z,,negative,bug,medium
3680400901,36355,Set favorite chart is only possible for the chart owners,open,"### Bug description

1. Create chart with a user
2. Log with another user which has access to the chart
3.  On welcome page, try to set chart as favorite

A 403 error occurs. When i look into the code, it's because i'm not the owner https://github.com/apache/superset/blob/5.0/superset/commands/chart/fave.py#L53. But shouldn't someone with access rights, but who is not an owner, be able to add it to their favorites ?


### Screenshots/recordings

Try to set favorite with a user which is not the owner: 

<img width=""710"" height=""353"" alt=""Image"" src=""https://github.com/user-attachments/assets/d7c986bb-bfbe-4693-8da2-501345f1f99f"" />


Error : 

<img width=""844"" height=""182"" alt=""Image"" src=""https://github.com/user-attachments/assets/4ef4a0d8-5367-4afb-b0ad-df29faaca6c3"" />

<img width=""459"" height=""107"" alt=""Image"" src=""https://github.com/user-attachments/assets/14246a57-81ea-4fd8-918b-d876fcbf81fe"" />

### Superset version

5.0.0

### Python version

3.11

### Node version

18 or greater

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",brenot-a,3,"home:favorite, global:users",https://github.com/apache/superset/issues/36355,2025-12-01T10:49:06Z,,negative,bug,medium
3677053888,36337,"Type '""table""' is not assignable to type 'DatasourceType'.",closed,"### Bug description

Hi bot/people.

I managed to get SS run in my work computer with arch WSL and now want to get it to run in my home computer with native Archlinux.

Ran:

docker compose -f docker-compose-non-dev.yml up

and just when ending the node compiling stuff (99.9%) i got:

189.6 <s> [webpack.Progress] 99% cache shutdown IdleFileCachePlugin serialize pack
200.7 <s> [webpack.Progress] 99% cache shutdown IdleFileCachePlugin stored
200.7 <s> [webpack.Progress] 99% cache shutdown
200.7 <s> [webpack.Progress] 100% 
200.7 
202.3 1030 assets
202.3 13946 modules
202.3 
202.3 ERROR in ./plugins/legacy-preset-chart-deckgl/src/layers/Polygon/transformProps.test.ts:58:19
202.3 TS2322: Type '""table""' is not assignable to type 'DatasourceType'.
202.3     56 |       },
202.3     57 |     ],
202.3   > 58 |     datasource: { type: 'table' as const, id: 1 },
202.3        |                   ^^^^
202.3     59 |     height: 400,
202.3     60 |     width: 600,
202.3     61 |     hooks: {},
202.3 
202.3 webpack 5.102.1 compiled with 1 error in 185394 ms
------
failed to solve: process ""/bin/sh -c if [ \""${DEV_MODE}\"" = \""false\"" ]; then         echo \""Running 'npm run ${BUILD_CMD}'\"";         npm run ${BUILD_CMD};     else         echo \""Skipping 'npm run ${BUILD_CMD}' in dev mode\"";     fi;"" did not complete successfully: exit code: 1


I already made this build process twice, removing the volumes in each case. (in case you bot suggest me to do that).

Thanks.

### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [ ] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",GAZ082,3,"validation:required, viz:charts:deck.gl",https://github.com/apache/superset/issues/36337,2025-11-29T20:00:50Z,2025-12-02T18:13:49Z,negative,bug,high
3675447233,36329,2nd regression between version 5.0.0 and version 6.0.0 of deck.gl Polygon -> Downlaod as image,open,"### Bug description

With version 6.0.0rc3, when I export my deck.gl Polygon card as an image, the resulting image no longer contains a white background at the back of the map legend. Unlike v.5.0.0, which keeps the background white. 1st problem.

The second problem visible in the resulting image is a residue of the tooltip. In fact, this problem comes from the behavior of the tooltips. If polygons cover the entire map frame, the tooltip will always be displayed, even if the pointer goes outside the frame. Therefore, when you export, you don‚Äôt know how to do otherwise than having a tooltip in the image. Here, it is not a regression. The problem is also observed in version 5.0.0.

### Screenshots/recordings

<img width=""983"" height=""918"" alt=""Image"" src=""https://github.com/user-attachments/assets/0627c0de-91f1-4159-a3e7-f600899048bc"" />
=======================================================================
=======================================================================
=======================================================================

<img width=""1042"" height=""893"" alt=""Image"" src=""https://github.com/user-attachments/assets/5018cd4f-2d60-47c5-be6f-590592083838"" />

### Superset version

master / latest-dev

### Python version

3.10

### Node version

Not applicable

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",SupersetOdT,2,"viz:charts:deck.gl, viz:charts:export",https://github.com/apache/superset/issues/36329,2025-11-28T16:44:42Z,,negative,bug,medium
3675316187,36328,Escaping the % character as %25 in the password within the connection string does not work,open,"### Bug description

When establishing a database connection, simply escaping the % character as %25 in the password within the connection string does not work.  
The root cause was identified in `superset/models/core.py`. The error occurs in the `sqlalchemy_uri_decrypted` function at the statement `return str(conn)`.  str(conn) make %25 to % and then make_url() make % disappear. 
A workaround is replacing %25 by %2525.


### Screenshots/recordings

_No response_

### Superset version

master / 6.0rc3

### Python version

3.11

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",i-love-thinking,3,"validation:required, data:databases",https://github.com/apache/superset/issues/36328,2025-11-28T15:48:29Z,,negative,bug,medium
3675206610,36326,Regression between version 5.0.0 and version 6.0.0 of deck.gl Polygon,open,"### Bug description

The ability to define a specific symbology for polygon outline (""Stroke Color) has been removed from deck.gl Polygon in Superset version 6.0.0rc3.

### Screenshots/recordings

<img width=""577"" height=""820"" alt=""Image"" src=""https://github.com/user-attachments/assets/b56d56a2-f1c1-4129-9276-4dc1d697a226"" />
========================================================================
========================================================================
========================================================================
<img width=""304"" height=""781"" alt=""Image"" src=""https://github.com/user-attachments/assets/23574e24-0f2b-440f-a768-277a9f87a523"" />

### Superset version

5.0.0

### Python version

3.10

### Node version

Not applicable

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",SupersetOdT,5,"#bug:regression, viz:charts:deck.gl",https://github.com/apache/superset/issues/36326,2025-11-28T15:04:45Z,,negative,bug,high
3675055367,36325,X axis all label is not showing even though data is there,open,"### Bug description

X axis all label is not showing even though data is there
In Area chart
i am getting complete label of x axis for time grain field(day,week)
showing only n,n+4,..... etc
Apache superset version - 4.1.1 & 5.0.0

### Screenshots/recordings

<img width=""1919"" height=""847"" alt=""Image"" src=""https://github.com/user-attachments/assets/29848682-3669-47a0-ae38-ff203d01b3c3"" />

### Superset version

4.1.3

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [ ] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",manikandan-362k,11,viz:charts:area,https://github.com/apache/superset/issues/36325,2025-11-28T14:09:16Z,,negative,bug,medium
3674752730,36324,[UI Inconsistency] Three-dot menu button behavior and styling across different pages,open,"## Screenshot

<img width=""381"" height=""176"" alt=""Image"" src=""https://github.com/user-attachments/assets/9be6e854-6075-40b4-b827-dbfd8fa50e85"" />

<img width=""415"" height=""476"" alt=""Image"" src=""https://github.com/user-attachments/assets/6f521c93-8bbc-445b-a572-d6b6563aa30e"" />

## Description

There is a noticeable UI inconsistency in the three-dot menu button (kebab menu) behavior and styling between the Welcome page and Dashboard page cards.

#### Current Behavior
Welcome Page (Home):
- Styling: Button color uses colorPrimaryText theme token
- Interaction: Menu opens on hover
- Location: Card three-dot menus

Dashboard Page:
- Styling: Button color uses colorTextLabel theme token
- Interaction: Menu opens on click
- Location: Chart card three-dot menus

#### Expected Behavior
The three-dot menu button should have consistent:
- Color scheme (using the same theme token across all pages)
- Interaction pattern (either always hover or always click)
",innovark37,2,#bug:cosmetic,https://github.com/apache/superset/issues/36324,2025-11-28T12:26:56Z,,negative,bug,medium
3672721186,36311,http://localhost:8088/superset/welcome/ blank (with hidden html).,closed,"### Bug description

Hi there. I am working with Archlinux in a WSL. Managed to get it running a couple of time but now even after deleting everytinng, purging all docker related stuff, I guess the superset-frontend, backend, etc. are not starting.

I followed the quickstart guide, with the branch 5.0.0, and the non-env docker compose file. Added oracledb and pymssql to the requirements txt.

The http://localhost:8088 is just blank, checking the code there is some hidden HTML elements, and that's it.

I tried with normal user, super user, to no avail. These are the containers running:

```
CONTAINER ID   IMAGE                           COMMAND                  CREATED          STATUS                      PORTS                                         NAMES
af0b279b48a1   superset-superset               ""/app/docker/docker-‚Ä¶""   14 minutes ago   Up 11 minutes (unhealthy)   0.0.0.0:8088->8088/tcp, [::]:8088->8088/tcp   superset_app
cb81e648d3dc   superset-superset-worker        ""/app/docker/docker-‚Ä¶""   14 minutes ago   Up 11 minutes (healthy)     8088/tcp                                      superset_worker
921458e5c8a3   superset-superset-worker-beat   ""/app/docker/docker-‚Ä¶""   14 minutes ago   Up 11 minutes               8088/tcp                                      superset_worker_beat
a1c63c9a42a7   redis:7                         ""docker-entrypoint.s‚Ä¶""   14 minutes ago   Up 14 minutes               6379/tcp                                      superset_cache
72294d36d97a   postgres:15                     ""docker-entrypoint.s‚Ä¶""   14 minutes ago   Up 14 minutes               5432/tcp                                      superset_db
```

Attached the full output.

[output.txt](https://github.com/user-attachments/files/23809861/output.txt)

Any tip is welcomed! Thanks!


### Screenshots/recordings

_No response_

### Superset version

5.0.0

### Python version

3.11

### Node version

18 or greater

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [ ] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",GAZ082,3,infra:webserver,https://github.com/apache/superset/issues/36311,2025-11-27T18:52:08Z,2025-11-27T20:44:41Z,negative,bug,high
3672466577,36310,Pie Chart Default Tooltip Does Not Have Spaces,closed,"## Screenshot

<img width=""647"" height=""296"" alt=""Image"" src=""https://github.com/user-attachments/assets/2abac722-4d23-4539-be8a-9dce48ad34cd"" />

## Description

The values should be separated. Here, the count is 57, and the percentage is 95.00. Add whitespaces in between.
",TobSchwa94,3,"good first issue, viz:charts:pie, viz:charts:tooltip",https://github.com/apache/superset/issues/36310,2025-11-27T17:11:34Z,2025-12-08T17:50:45Z,negative,bug,medium
3670668096,36305,"Import CSV ; The ""schema"" field required or not --> 2 datasets for 1 table",open,"### Bug description

## Description

The ""schema"" field is not required :

<img width=""496"" height=""845"" alt=""Image"" src=""https://github.com/user-attachments/assets/f238119a-e4dc-419b-8c30-6cf73817abd7"" />

with version 4 value 'public' was set by default but with V5.0.0, the default value is not set

<img width=""1208"" height=""891"" alt=""Image"" src=""https://github.com/user-attachments/assets/682e7e30-02f2-48ca-a20b-288ce6e1cf0d"" />

The error message should precise 

The import is OK if user set a schema but 2 datasets are existing for 1 table

### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [ ] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",xavier-GitHub76,9,"validation:required, good first issue, data:csv",https://github.com/apache/superset/issues/36305,2025-11-27T09:52:58Z,,negative,bug,medium
3670597291,36304,ENABLE_SUPERSET_META_DB feature works incorrectly,open,"### Bug description

I use MS SQL and MongoDb (through Trino).

When I try to execute query like this one below:

SELECT t1.DeviceId, t2.timestamp, t1.Name, t2.hash, t1.DeviceTypeId
FROM ""MagistralDb.dbo.Devices"" AS t1
INNER JOIN ""Mongo.bluetoothdb.scans"" as t2 ON t2.deviceid = t1.DeviceId
**WHERE t1.DeviceId = 2560 OR t1.DeviceId = 2562 OR t1.DeviceId = 2564 OR t1.DeviceId = 2565**

I got the message: **""The query returned no data""**

If I cut ""WHERE"" condition to ""WHERE t1.DeviceId = 2560"", so my query is:

SELECT t1.DeviceId, t2.timestamp, t1.Name, t2.hash, t1.DeviceTypeId
FROM ""MagistralDb.dbo.Devices"" AS t1
INNER JOIN ""Mongo.bluetoothdb.scans"" as t2 ON t2.deviceid = t1.DeviceId
**WHERE t1.DeviceId = 2560**

I got **1K records**

### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",harry-flw,4,data:connect:trino,https://github.com/apache/superset/issues/36304,2025-11-27T09:31:42Z,,negative,bug,high
3668133814,36294,"Bug : Celery broken with Redis Cluster in 5.0.0, async queries and reports not working",open,"### Bug description

I'm not sure if this is a bug or a configuration issue, but here's what we're experiencing...

We're running into an issue with the new 5.0.0 release where Celery completely breaks when we try to use a Redis Cluster as the broker and result backend. This is taking down two critical features for us:
1.SQL Lab async queries just fail with ""Failed to start remote query on a worker""
2.All scheduled reports stop working and won't generate

### Screenshots/recordings

Here's the relevant part from our superset_config.py 
# Trying to use Redis Cluster for Celery
class CeleryConfig(object):
    broker_url = ""redis://our-redis-cluster-host:port""  # Our cluster connection string
    result_backend = ""redis://our-redis-cluster-host:port""  # Same here
    imports = (""superset.sql_lab"", ""superset.tasks.scheduler"",)
    worker_prefetch_multiplier = 10
    task_acks_late = True

CELERY_CONFIG = CeleryConfig

# Enable async SQL Lab
SQLLAB_EXECUTOR = ""superset.sql_lab.CeleryAsyncExecutor""

# Enable reports
FEATURE_FLAGS = {
    ""ENABLE_ASYNC_QUERIES"": True,
    ""ASYNC_QUERIES"": True,
    ""GLOBAL_ASYNC_QUERIES"": False,
}


Troubleshooting we've tried:

We even tried using the solo pool instead of prefork to avoid any potential cluster issues, by running:

celery --app=superset.tasks.celery_app:app worker --pool=solo -O fair -c 4

But the issue persists - Celery still fails to work properly with the Redis Cluster setup.

What we expect:

Pretty straightforward - we expect Superset 5.0.0 to properly support Redis Cluster as Celery backend so async queries and reports work normally.

### Superset version

5.0.0

### Python version

3.11

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",Umbrella-zero,3,"#bug:newfeature, global:async-query",https://github.com/apache/superset/issues/36294,2025-11-26T16:02:53Z,,negative,bug,high
3667827227,36292,Bug: Custom-SQL Filter with ‚ÄúWHERE/IN‚Äù on Snowflake + Aggregation ‚Üí Data Error / No Results,open,"### Bug description

Issue:
When using Superset with a Snowflake data source, applying a Custom SQL filter (e.g. LOAN_ID IN ('...')) on a chart using aggregation leads to a data error or no results. Using the same filter with the ‚ÄúSimple‚Äù filter option works correctly.

Steps to Reproduce:

1. Use Snowflake as the database backend.
2. Have a table with a column LOAN_ID (string or varchar) and a numeric metric (e.g. PRINCIPALBALANCE).
3. Create a chart (e.g. Table visualization) in ‚Äúaggregate‚Äù mode, grouping by LOAN_ID.
4. Apply a filter on LOAN_ID using the ‚ÄúCustom SQL‚Äù filter type, with condition like:
```
LOAN_ID IN ('YAPN927')
```
5. Run the query.


Expected Behavior:
Filter should behave exactly like the built-in ‚ÄúSimple‚Äù filter ‚Äî return rows where LOAN_ID = 'YAPN927'.

Actual Behavior:
The chart returns a data error. The generated query payload contains the filter under extras.where, which seems incompatible with aggregation mode + Snowflake dialect.

Additional Context / Notes:

- This works if you use the ‚ÄúSimple‚Äù filter UI for LOAN_ID.
- Snowflake requires proper quoting for identifiers (e.g. ""LOAN_ID""), which Superset does correctly when using simple filters, but fails when using custom-SQL filters in this context.
- I attempted repetition with different quoting (e.g. ""LOAN_ID"", CAST(...), etc.), but error persists.
- Superset version: 6.0.0
- Database: Snowflake
- This appears to be a generic issue combining: Snowflake dialect, custom-SQL filters, aggregation charts, and Superset‚Äôs query builder logic.

Suggested Fix / Hypothesis:

- Ensure that when building SQL for custom filters + aggregation + Snowflake, Superset quotes identifiers properly (e.g. ""LOAN_ID"").
- Avoid placing custom filters into extras.where / HAVING for aggregated queries; instead inject them into WHERE clause before grouping.

Relevant Payload / Example:
Valid payload when run with ""Simple"" filter:
```
{
    ""datasource"": {
        ""id"": 8,
        ""type"": ""table""
    },
    ""force"": false,
    ""queries"": [
        {
            ""filters"": [
                {
                    ""col"": ""CLOSEDDATE"",
                    ""op"": ""TEMPORAL_RANGE"",
                    ""val"": ""No filter""
                },
                {
                    ""col"": ""LAST_REPAYMENT_DATE"",
                    ""op"": ""TEMPORAL_RANGE"",
                    ""val"": ""Current year""
                },
                {
                    ""col"": ""LOAN_ID"",
                    ""op"": ""IN"",
                    ""val"": [
                        ""YAPN927""
                    ]
                }
            ],
            ""extras"": {
                ""time_grain_sqla"": ""P1D"",
                ""having"": """",
                ""where"": """"
            },
            ""applied_time_extras"": {},
            ""columns"": [
                {
                    ""timeGrain"": ""P1D"",
                    ""columnType"": ""BASE_AXIS"",
                    ""sqlExpression"": ""LAST_REPAYMENT_DATE"",
                    ""label"": ""LAST_REPAYMENT_DATE"",
                    ""expressionType"": ""SQL""
                },
                ""LOAN_ID""
            ],
            ""metrics"": [
                {
                    ""aggregate"": ""SUM"",
                    ""column"": {
                        ""advanced_data_type"": null,
                        ""certification_details"": null,
                        ""certified_by"": null,
                        ""column_name"": ""PRINCIPALBALANCE"",
                        ""description"": null,
                        ""expression"": null,
                        ""filterable"": true,
                        ""groupby"": true,
                        ""id"": 119,
                        ""is_certified"": false,
                        ""is_dttm"": false,
                        ""python_date_format"": null,
                        ""type"": null,
                        ""type_generic"": null,
                        ""uuid"": ""9501808a-b14f-4a97-b1d7-4ef513241374"",
                        ""verbose_name"": null,
                        ""warning_markdown"": null
                    },
                    ""datasourceWarning"": false,
                    ""expressionType"": ""SIMPLE"",
                    ""hasCustomLabel"": false,
                    ""label"": ""SUM(PRINCIPALBALANCE)"",
                    ""optionName"": ""metric_0b47pprdc74q_2d7hxhmvo2"",
                    ""sqlExpression"": null
                }
            ],
            ""orderby"": [
                [
                    {
                        ""aggregate"": ""SUM"",
                        ""column"": {
                            ""advanced_data_type"": null,
                            ""certification_details"": null,
                            ""certified_by"": null,
                            ""column_name"": ""PRINCIPALBALANCE"",
                            ""description"": null,
                            ""expression"": null,
                            ""filterable"": true,
                            ""groupby"": true,
                            ""id"": 119,
                            ""is_certified"": false,
                            ""is_dttm"": false,
                            ""python_date_format"": null,
                            ""type"": null,
                            ""type_generic"": null,
                            ""uuid"": ""9501808a-b14f-4a97-b1d7-4ef513241374"",
                            ""verbose_name"": null,
                            ""warning_markdown"": null
                        },
                        ""datasourceWarning"": false,
                        ""expressionType"": ""SIMPLE"",
                        ""hasCustomLabel"": false,
                        ""label"": ""SUM(PRINCIPALBALANCE)"",
                        ""optionName"": ""metric_0b47pprdc74q_2d7hxhmvo2"",
                        ""sqlExpression"": null
                    },
                    false
                ]
            ],
            ""annotation_layers"": [],
            ""row_limit"": 10000,
            ""series_limit"": 0,
            ""group_others_when_limit_reached"": false,
            ""order_desc"": true,
            ""url_params"": {
                ""form_data_key"": ""0tlamyc6LXk"",
                ""slice_id"": ""5""
            },
            ""custom_params"": {},
            ""custom_form_data"": {},
            ""post_processing"": [],
            ""time_offsets"": []
        }
    ],
    ""form_data"": {
        ""datasource"": ""8__table"",
        ""viz_type"": ""table"",
        ""slice_id"": 5,
        ""url_params"": {
            ""form_data_key"": ""0tlamyc6LXk"",
            ""slice_id"": ""5""
        },
        ""query_mode"": ""aggregate"",
        ""groupby"": [
            ""LAST_REPAYMENT_DATE"",
            ""LOAN_ID""
        ],
        ""time_grain_sqla"": ""P1D"",
        ""temporal_columns_lookup"": {
            ""CLOSEDDATE"": true,
            ""CREATIONDATE"": true,
            ""APPROVEDDATE"": true,
            ""LASTMODIFIEDDATE"": true,
            ""LAST_EXPECTED_REPAYMENT"": true,
            ""LOAN_REPAID_DATE"": true,
            ""LAST_REPAYMENT_DATE"": true,
            ""DISBURSEMENTDATE"": true,
            ""_LAST_REPAYMENT_UPDATE_DATE"": true
        },
        ""metrics"": [
            {
                ""aggregate"": ""SUM"",
                ""column"": {
                    ""advanced_data_type"": null,
                    ""certification_details"": null,
                    ""certified_by"": null,
                    ""column_name"": ""PRINCIPALBALANCE"",
                    ""description"": null,
                    ""expression"": null,
                    ""filterable"": true,
                    ""groupby"": true,
                    ""id"": 119,
                    ""is_certified"": false,
                    ""is_dttm"": false,
                    ""python_date_format"": null,
                    ""type"": null,
                    ""type_generic"": null,
                    ""uuid"": ""9501808a-b14f-4a97-b1d7-4ef513241374"",
                    ""verbose_name"": null,
                    ""warning_markdown"": null
                },
                ""datasourceWarning"": false,
                ""expressionType"": ""SIMPLE"",
                ""hasCustomLabel"": false,
                ""label"": ""SUM(PRINCIPALBALANCE)"",
                ""optionName"": ""metric_0b47pprdc74q_2d7hxhmvo2"",
                ""sqlExpression"": null
            }
        ],
        ""all_columns"": [],
        ""percent_metrics"": [],
        ""adhoc_filters"": [
            {
                ""expressionType"": ""SIMPLE"",
                ""subject"": ""CLOSEDDATE"",
                ""operator"": ""TEMPORAL_RANGE"",
                ""comparator"": ""No filter"",
                ""clause"": ""WHERE"",
                ""sqlExpression"": null,
                ""isExtra"": false,
                ""isNew"": false,
                ""datasourceWarning"": false,
                ""filterOptionName"": ""filter_mkc3y3o9def_i9fe2leyva""
            },
            {
                ""expressionType"": ""SIMPLE"",
                ""subject"": ""LAST_REPAYMENT_DATE"",
                ""operator"": ""TEMPORAL_RANGE"",
                ""comparator"": ""Current year"",
                ""clause"": ""WHERE"",
                ""sqlExpression"": null,
                ""isExtra"": false,
                ""isNew"": false,
                ""datasourceWarning"": false,
                ""filterOptionName"": ""filter_rf8ruxla9s8_j1s0kqe341q""
            },
            {
                ""expressionType"": ""SIMPLE"",
                ""subject"": ""LOAN_ID"",
                ""operator"": ""IN"",
                ""operatorId"": ""IN"",
                ""comparator"": [
                    ""YAPN927""
                ],
                ""clause"": ""WHERE"",
                ""sqlExpression"": null,
                ""isExtra"": false,
                ""isNew"": false,
                ""datasourceWarning"": false,
                ""filterOptionName"": ""filter_8scjx5i79k3_jbr5a9lhxv""
            }
        ],
        ""order_by_cols"": [],
        ""order_desc"": true,
        ""server_page_length"": 10,
        ""row_limit"": 10000,
        ""percent_metric_calculation"": ""row_limit"",
        ""table_timestamp_format"": ""smart_date"",
        ""allow_render_html"": true,
        ""show_cell_bars"": true,
        ""color_pn"": true,
        ""comparison_color_scheme"": ""Green"",
        ""comparison_type"": ""values"",
        ""extra_form_data"": {},
        ""force"": false,
        ""result_format"": ""json"",
        ""result_type"": ""full""
    },
    ""result_format"": ""json"",
    ""result_type"": ""full""
}
```
Invalid payload when using ""Custom SQL"":
```
{
    ""datasource"": {
        ""id"": 8,
        ""type"": ""table""
    },
    ""force"": false,
    ""queries"": [
        {
            ""filters"": [
                {
                    ""col"": ""CLOSEDDATE"",
                    ""op"": ""TEMPORAL_RANGE"",
                    ""val"": ""No filter""
                },
                {
                    ""col"": ""LAST_REPAYMENT_DATE"",
                    ""op"": ""TEMPORAL_RANGE"",
                    ""val"": ""Current year""
                }
            ],
            ""extras"": {
                ""having"": """",
                ""where"": ""(LOAN_ID In ('YAPN927'))""
            },
            ""applied_time_extras"": {},
            ""columns"": [
                ""LOAN_ID""
            ],
            ""metrics"": [
                {
                    ""aggregate"": ""SUM"",
                    ""column"": {
                        ""advanced_data_type"": null,
                        ""certification_details"": null,
                        ""certified_by"": null,
                        ""column_name"": ""PRINCIPALBALANCE"",
                        ""description"": null,
                        ""expression"": null,
                        ""filterable"": true,
                        ""groupby"": true,
                        ""id"": 119,
                        ""is_certified"": false,
                        ""is_dttm"": false,
                        ""python_date_format"": null,
                        ""type"": null,
                        ""type_generic"": null,
                        ""uuid"": ""9501808a-b14f-4a97-b1d7-4ef513241374"",
                        ""verbose_name"": null,
                        ""warning_markdown"": null
                    },
                    ""datasourceWarning"": false,
                    ""expressionType"": ""SIMPLE"",
                    ""hasCustomLabel"": false,
                    ""label"": ""SUM(PRINCIPALBALANCE)"",
                    ""optionName"": ""metric_0b47pprdc74q_2d7hxhmvo2"",
                    ""sqlExpression"": null
                }
            ],
            ""orderby"": [
                [
                    {
                        ""aggregate"": ""SUM"",
                        ""column"": {
                            ""advanced_data_type"": null,
                            ""certification_details"": null,
                            ""certified_by"": null,
                            ""column_name"": ""PRINCIPALBALANCE"",
                            ""description"": null,
                            ""expression"": null,
                            ""filterable"": true,
                            ""groupby"": true,
                            ""id"": 119,
                            ""is_certified"": false,
                            ""is_dttm"": false,
                            ""python_date_format"": null,
                            ""type"": null,
                            ""type_generic"": null,
                            ""uuid"": ""9501808a-b14f-4a97-b1d7-4ef513241374"",
                            ""verbose_name"": null,
                            ""warning_markdown"": null
                        },
                        ""datasourceWarning"": false,
                        ""expressionType"": ""SIMPLE"",
                        ""hasCustomLabel"": false,
                        ""label"": ""SUM(PRINCIPALBALANCE)"",
                        ""optionName"": ""metric_0b47pprdc74q_2d7hxhmvo2"",
                        ""sqlExpression"": null
                    },
                    false
                ]
            ],
            ""annotation_layers"": [],
            ""row_limit"": 10000,
            ""series_limit"": 0,
            ""group_others_when_limit_reached"": false,
            ""order_desc"": true,
            ""url_params"": {
                ""slice_id"": ""5""
            },
            ""custom_params"": {},
            ""custom_form_data"": {},
            ""post_processing"": [],
            ""time_offsets"": []
        }
    ],
    ""form_data"": {
        ""datasource"": ""8__table"",
        ""viz_type"": ""table"",
        ""slice_id"": 5,
        ""url_params"": {
            ""slice_id"": ""5""
        },
        ""query_mode"": ""aggregate"",
        ""groupby"": [
            ""LOAN_ID""
        ],
        ""temporal_columns_lookup"": {
            ""CLOSEDDATE"": true,
            ""CREATIONDATE"": true,
            ""APPROVEDDATE"": true,
            ""LASTMODIFIEDDATE"": true,
            ""LAST_EXPECTED_REPAYMENT"": true,
            ""LOAN_REPAID_DATE"": true,
            ""LAST_REPAYMENT_DATE"": true,
            ""DISBURSEMENTDATE"": true,
            ""_LAST_REPAYMENT_UPDATE_DATE"": true
        },
        ""metrics"": [
            {
                ""aggregate"": ""SUM"",
                ""column"": {
                    ""advanced_data_type"": null,
                    ""certification_details"": null,
                    ""certified_by"": null,
                    ""column_name"": ""PRINCIPALBALANCE"",
                    ""description"": null,
                    ""expression"": null,
                    ""filterable"": true,
                    ""groupby"": true,
                    ""id"": 119,
                    ""is_certified"": false,
                    ""is_dttm"": false,
                    ""python_date_format"": null,
                    ""type"": null,
                    ""type_generic"": null,
                    ""uuid"": ""9501808a-b14f-4a97-b1d7-4ef513241374"",
                    ""verbose_name"": null,
                    ""warning_markdown"": null
                },
                ""datasourceWarning"": false,
                ""expressionType"": ""SIMPLE"",
                ""hasCustomLabel"": false,
                ""label"": ""SUM(PRINCIPALBALANCE)"",
                ""optionName"": ""metric_0b47pprdc74q_2d7hxhmvo2"",
                ""sqlExpression"": null
            }
        ],
        ""all_columns"": [],
        ""percent_metrics"": [],
        ""adhoc_filters"": [
            {
                ""expressionType"": ""SIMPLE"",
                ""subject"": ""CLOSEDDATE"",
                ""operator"": ""TEMPORAL_RANGE"",
                ""comparator"": ""No filter"",
                ""clause"": ""WHERE"",
                ""sqlExpression"": null,
                ""isExtra"": false,
                ""isNew"": false,
                ""datasourceWarning"": false,
                ""filterOptionName"": ""filter_mkc3y3o9def_i9fe2leyva""
            },
            {
                ""expressionType"": ""SIMPLE"",
                ""subject"": ""LAST_REPAYMENT_DATE"",
                ""operator"": ""TEMPORAL_RANGE"",
                ""comparator"": ""Current year"",
                ""clause"": ""WHERE"",
                ""sqlExpression"": null,
                ""isExtra"": false,
                ""isNew"": false,
                ""datasourceWarning"": false,
                ""filterOptionName"": ""filter_rf8ruxla9s8_j1s0kqe341q""
            },
            {
                ""expressionType"": ""SQL"",
                ""sqlExpression"": ""LOAN_ID In ('YAPN927')"",
                ""clause"": ""WHERE"",
                ""subject"": null,
                ""operator"": null,
                ""comparator"": null,
                ""isExtra"": false,
                ""isNew"": false,
                ""datasourceWarning"": false,
                ""filterOptionName"": ""filter_fai50u42ycu_3v0yosy8u15""
            }
        ],
        ""order_by_cols"": [],
        ""row_limit"": 10000,
        ""percent_metric_calculation"": ""row_limit"",
        ""table_timestamp_format"": ""smart_date"",
        ""allow_render_html"": true,
        ""show_cell_bars"": true,
        ""color_pn"": true,
        ""comparison_color_scheme"": ""Green"",
        ""comparison_type"": ""values"",
        ""extra_form_data"": {},
        ""force"": false,
        ""result_format"": ""json"",
        ""result_type"": ""full""
    },
    ""result_format"": ""json"",
    ""result_type"": ""full""
}
```


Why this matters:
This bug prevents using custom filters reliably on Snowflake when aggregation is involved ‚Äî significantly reducing Superset‚Äôs usability with Snowflake for filtered/aggregated dashboards.


### Screenshots/recordings

""Simple"" filter: 
<img width=""1917"" height=""989"" alt=""Image"" src=""https://github.com/user-attachments/assets/027efcd3-ecf2-4a6b-bf1d-321cb153defe"" />

""Custom SQL"" filter
<img width=""1915"" height=""981"" alt=""Image"" src=""https://github.com/user-attachments/assets/f650403e-58b3-4520-a9f0-340e86101e0a"" />

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",shalom-t,4,"data:connect:snowflake, viz:charts:table",https://github.com/apache/superset/issues/36292,2025-11-26T14:49:12Z,,negative,bug,high
3667694110,36291,ALLOW_FULL_CSV_EXPORT flag doesn't work,closed,"### Bug description

In version 5.0.0 the ALLOW_FULL_CSV_EXPORT flag does not work, we have it configured with True but it ignores it

<img width=""365"" height=""172"" alt=""Image"" src=""https://github.com/user-attachments/assets/0d74835b-614d-4907-9307-4e8584e51e30"" />

CSV file exports only have what is filtered in the search,  only the 13 records of the query <img width=""1527"" height=""636"" alt=""Image"" src=""https://github.com/user-attachments/assets/eb6cfda2-acfb-426d-8fc2-15017b882e49"" />

### Screenshots/recordings

_No response_

### Superset version

5.0.0

### Python version

3.10

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",slemos-cmyk,4,data:csv,https://github.com/apache/superset/issues/36291,2025-11-26T14:13:47Z,2025-12-02T22:50:38Z,negative,bug,high
3666214354,36285,"OAuth2 login button not displaying ""icon"", except google",closed,"## Screenshot

<img width=""471"" height=""250"" alt=""Image"" src=""https://github.com/user-attachments/assets/aed662eb-686d-48e4-ad4e-486b140d7254"" />

## Description

I've setup login with oauth2, once upon a time with google and now with keycloak, it works fine.

Config look slike
```py
OAUTH_PROVIDERS=[

'name':'Keycloak',
'icon': 'fa-key',
# etc.
]

```


With Google I used to set icon to `fa-google` which I *guess* is supposed to be the icon included in FontAwesome ?

Anyway : google icon displayed just fine.

Whatever else I try instead does not show up. Tried fa-address-card, or some others fa-... thing.

Maybe I'm wrong, it's not font-awesome at all and only some subset of icons are available ? In which case, which ones ?


",squalou,1,authentication,https://github.com/apache/superset/issues/36285,2025-11-26T07:25:06Z,2025-11-26T08:12:43Z,neutral,bug,medium
3665939236,36282,Unable to list dashboards using API api/v1/dashboard which are in draft status,closed,"### Bug description

Hi Team,

I am unable to list dashboards using API api/v1/dashboard which are in draft status. I have a custom user and given permissions as below . Please let me know if any additional permissions need to be added.     (""can_write"", ""Chart""),
    (""can_write"", ""Dataset""),
    (""can_write"", ""Dashboard""),
    (""can_write"", ""Database""),
    (""can_read"", ""Chart""),
    (""can_read"", ""Dataset""),
    (""can_read"", ""Dashboard""),
    (""can_read"", ""Database""),
    (""can_grant_guest_token"", ""SecurityRestApi""),
    (""can_export"", ""ImportExportRestApi""),
    (""can_read"", ""SecurityRestApi""),
    (""can_export"", ""Dashboard""),
    (""all_database_access"", ""all_database_access""),

### Screenshots/recordings

_No response_

### Superset version

5.0.0

### Python version

3.11

### Node version

18 or greater

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",Devika7733,4,"listview:dashboards, api",https://github.com/apache/superset/issues/36282,2025-11-26T05:57:41Z,2025-12-01T18:08:57Z,negative,bug,medium
3664590945,36276,[SIP-193] Proposal for Dynamic Currency Handling,open,"## [SIP-193] Proposal for Dynamic Currency Handling

### Motivation

Superset requires manual currency formatting for each metric in every chart. This creates several problems:

1. **Repetitive configuration** - Users must set currency formatting individually for each chart, even when all charts use the same currency
2. **Error-prone** - Easy to forget currency formatting or select the wrong currency symbol
3. **No multi-currency support** - Table visualizations cannot display different currency symbols per row based on data
4. **Inflexible dashboards** - When filters change the currency context (e.g., filtering by country), currency symbols don't adapt

### Proposed Change

#### Dataset-Level Currency Configuration

Add a new configuration option in the Dataset Editor that allows users to specify which column contains currency codes (e.g., USD, EUR, GBP). This creates a single source of truth for currency information.

#### Automatic Currency Symbol Detection

Superset will automatically normalize and map currency values:

- **Normalize non-standard inputs** - Values like ""euro"", ""‚Ç¨"", ""eur"" are normalized to ""EUR""
- **Map codes to symbols** - Currency codes are mapped to symbols ($, ‚Ç¨, ¬£, ¬•, C$, etc.) using the **ISO 4217** standard
- **No manual configuration required** - Once the currency column is identified, symbol detection is automatic

#### Currency Behavior Modes in Charts

In the chart builder (Explore), the currency format dropdown offers two behavior modes:

1. **Automatic mode** (new)
   - Uses the dataset's configured currency code column
   - Shows the correct symbol when exactly one currency is present in the queried data
   - Shows neutral formatting (no symbol) when mixed currencies are present
   - Prevents incorrect symbols in KPIs and aggregated charts

2. **Static mode** (existing behavior)
   - User manually selects a fixed symbol (e.g., ""$"", ""‚Ç¨"", ""¬£"")
   - Fully backward compatible for existing dashboards
   - Symbol displays regardless of underlying data

#### Expected Behavior

| Scenario | Result |
|----------|--------|
| All queried data has same currency (e.g., USD) | Display `$` symbol |
| Data contains mixed currencies (USD, EUR, GBP) | No symbol (neutral formatting) |
| Dashboard filter narrows to single currency | Symbol appears dynamically |
| No currency column configured in dataset | No symbol |

#### Chart-Level vs Row-Level Detection

For **aggregated visualizations** (Big Number, Gauge, Pie, etc.), currency detection happens at the chart level. This is because aggregated values (sums, averages) across mixed currencies are semantically meaningless - you shouldn't sum USD and EUR values. Chart-level detection correctly answers: ""Does this data have uniform currency?""

For **Table and Pivot Table** visualizations, row-level currency formatting is supported. Each row can display its own currency symbol based on the currency code column value:

| Amount | Currency |
|--------|----------|
| ‚Ç¨1,250.50 | EUR |
| $980.00 | USD |

This is useful when exploring detailed, multi-currency data.

#### Decimal Precision

Decimal precision remains fully user-controlled and works with both Automatic and Static currency modes. Users can choose:
- Adaptive decimals
- Fixed decimals (0, 0.0, 0.00, 0.000, etc.)

### New or Changed Public Interfaces

#### Dataset Model
- New optional field to store the currency code column reference

#### Dataset Editor UI
- New dropdown to identify the currency code column

#### Chart Controls
- New ""Automatic"" option in currency format dropdowns (uses dataset currency column)
- Existing static currency options remain unchanged
- Applicable to charts that display monetary values (Big Number, Time Series, Gauge, Pie, Table, Pivot Table, etc.)

#### REST API
- Dataset endpoints should accept and return the currency code column configuration

### New dependencies

None required. Currency code normalization and symbol mapping can use existing JavaScript Intl APIs with ISO 4217 currency codes.

### Migration Plan and Compatibility

- **Opt-in only** - Existing charts remain unchanged until users explicitly select ""Automatic""
- **Database migration** - Add nullable column to dataset table; no data transformation needed
- **Graceful degradation** - Missing or invalid configuration results in neutral formatting (no symbol)
- **No breaking changes** - All existing currency formatting continues to work

### Out of Scope

The following are explicitly **not** included in this proposal:

- Converting currencies between each other
- Managing FX (foreign exchange) rates
- Automatically converting values into a single reporting currency
- Historical FX logic

### Rejected Alternatives

1. **Chart-level currency column selector** - Rejected because it would require configuration on every chart, not solving the repetition problem

2. **Automatic currency detection without dataset configuration** - Rejected because reliably detecting currency columns by name or content patterns is error-prone and could produce unexpected results

3. **Per-cell currency formatting in all visualizations** - Rejected for aggregated charts because mixing currencies in aggregations is mathematically invalid; however, row-level formatting is supported for Table and Pivot Table charts where it makes semantic sense
",richardfogaca,4,"sip, viz:charts:pivot, design:proposal",https://github.com/apache/superset/issues/36276,2025-11-25T21:05:43Z,,neutral,feature_request,medium
3663727540,36268,Export to PDF fails with CSP error for dashboards with images,closed,"### Bug description

When using Talisman for CORS settings, you can restrict images and other files being loaded from specific domains, such as a CDN. These images can be included in dashboards using Markdown. However, when trying to export the dashboard to PDF, it fails, with a CSP error in the network tab of the browser.

I've tried with both Firefox and Chrome, on 5.0.0. I tried to test this with 6.0.0rc3, but I couldn't get my local installation to run (`docker compose` works, but then requests just hang infinite).

## Steps to reproduce
1. Enable Talisman in your settings: set `TALISMAN_ENABLED = True`, and add `https:` in the list `TALISMAN_DEV_CONFIG[""content_security_policy""][""img-src""]` to allow images from all domains (using HTTPS).
3. Create a new dashboard or edit an existing one
4. Add a Markdown block (or change an existing one)
5. Add an image. I've used: `![test](https://superset.apache.org/img/superset-logo-horiz-dark.svg)`
6. Make sure the Markdown block was saved as well on blur (this is a bit buggy I've noticed, it can revert to the old Markdown code if you don't properly click outside of the form element)
7. Save the dashboard
8. Confirm the dashboard shows the image, even after reloading the dashboard
9. On the 3 dots at the top right, select Download -> Export to PDF
10. Nothing happens, and the web browser shows a CSP error when trying to retrieve the image

Screenshots in email reports work fine, they show the embedded image.

I tried a lot of different options in my installation, and couldn't get it to work. I used ChatGPT a bit to talk through the problem, and its conclusion was that the endpoint that generates the PDF doesn't use the same Talisman configuration, but I don't know how to verify if that's indeed the problem.

### Screenshots/recordings

<img width=""1920"" height=""970"" alt=""Image"" src=""https://github.com/user-attachments/assets/3b76c79b-fd9a-4103-bee8-5880e9892292"" />

### Superset version

5.0.0

### Python version

3.10

### Node version

18 or greater

### Browser

Firefox

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",Gwildor,3,dashboard:export,https://github.com/apache/superset/issues/36268,2025-11-25T16:17:56Z,2025-11-26T09:34:34Z,negative,bug,high
3663696125,36267,"DrillDetailTable's pageSize is 50, but the pageSizeOptions allows the default 5,15,25,50,100",open,"### Bug description

On the Drill to details table of a chart, when you set the pageSize to lower than 50, you can overread the results by jumping to the last page. Also setting the pageSize to 100 only shows 50 rows.

The cause is that the pageSize is set to a constant value of 50, but the pageSizeOptions inherit a [5,15,25,50,100] valueset and the UI shows the pageSize as a user changeable value. 

One possible solution is to set the pageSizeOptions to ['50'] because it is the only valid option right now. This will cause the pageSize selector to have only one value.
DrillDetailPane.tsx 
  defaultPageSize={PAGE_SIZE}
++ pageSizeOptions={['50']}

I'm happy to make the adjustment, but please someone approve this!

### Screenshots/recordings

<img width=""866"" height=""706"" alt=""Image"" src=""https://github.com/user-attachments/assets/ef279900-e1a8-48f3-8c91-3c636ff0ea30"" />

### Superset version

master / latest-dev

### Python version

I don't know

### Node version

I don't know

### Browser

Not applicable

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",durban77,5,good first issue,https://github.com/apache/superset/issues/36267,2025-11-25T16:09:28Z,,negative,bug,medium
3662139998,36261,sql_lab role does not include can_estimate_query_cost and can_format_sql permissions,closed,"### Bug description

Summary

In Superset 5.0.0, the built-in sql_lab role does not include the required SQL Lab permissions:

- can estimate query cost on SQLLab
- can format sql on SQLLab

As a result, users with the built-in sql_lab role cannot use ""Estimate Query Cost"" or ""Format SQL"" in SQL Lab unless these permissions are manually added.

### Screenshots/recordings

_No response_

### Superset version

5.0.0

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",shunki-fujita,2,sqllab,https://github.com/apache/superset/issues/36261,2025-11-25T09:10:15Z,2025-12-08T22:40:39Z,neutral,bug,medium
3662139196,36260,sql_lab role does not include can_estimate_query_cost and can_format_sql permissions,closed,"### Bug description

Summary

In Superset 5.0.0, the built-in sql_lab role does not include the required SQL Lab permissions:

- can estimate query cost on SQLLab
- can format sql on SQLLab

As a result, users with the built-in sql_lab role cannot use ""Estimate Query Cost"" or ""Format SQL"" in SQL Lab unless these permissions are manually added.

### Screenshots/recordings

_No response_

### Superset version

5.0.0

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",shunki-fujita,1,sqllab,https://github.com/apache/superset/issues/36260,2025-11-25T09:10:01Z,2025-11-25T14:19:50Z,negative,bug,medium
3661904953,36258,[6.0.0‚ÄëRC2] Error tooltip doesn't appear above Server Page Length select when its value isn't integer,closed,"### Bug description
Error tooltip doesn't appear above Server Page Length select when its value isn't integer.

### Steps to reproduce
1. Deploy the Docker version of Superset based on 6.0.0rc2 (same on the master-branch build version).
2. Go to ""Charts"", create new Table chart with any dataset.
3. When new page is opened, find column with chart settings, select ""Data"".
4. Find ""Server pagination"" checkbox and check it.
5. Enter non-integer values into Server Page Length and Row limit and save them.

### Expected behavior
Both Server Page Length and Row limit selects have the same error tooltip: ""is expected to be an integer""

### Actual behavior
Only Row limit has ""is expected to be an integer"" error tooltip.

### Suggested solution
Add value validator legacyValidateInteger for Server Page Length, just like in Row limit.

### Screenshots/recordings

<img width=""286"" height=""175"" alt=""Image"" src=""https://github.com/user-attachments/assets/66320723-7d72-4d89-a528-e4808b858866"" />

<img width=""319"" height=""147"" alt=""Image"" src=""https://github.com/user-attachments/assets/572d8fdf-a420-40c7-a1f5-252cd30b1ed9"" />

### Superset version

master / latest-dev

### Python version

3.11

### Node version

18 or greater

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",innovark37,2,"#bug:cosmetic, explore:design",https://github.com/apache/superset/issues/36258,2025-11-25T07:57:19Z,2025-11-28T20:29:18Z,negative,bug,medium
3660556364,36244,"User importing a dashboard is incorrectly added as an owner, leading to unauthorized privilege escalation",open,"### Bug description

**Preconditions:**

- Two users: User 1 and User 2.

- A dashboard named ""Dashboard 1"" exists, owned by User 1.

- User 2 has a role with the ""can write on dashboard"" permission, which is also the permission that grants the ability to import dashboards.


**Steps to Reproduce:**

1. As User 2, export ""Dashboard 1"" (owned by User 1).

2. As User 2, import the previously exported dashboard file into the same Superset instance.

3. After the import is complete, navigate to the list of dashboards and open the imported dashboard.

4. Go to the dashboard's properties to view the list of owners.

**Result:**
The list of owners for the imported dashboard includes User 2 in addition to the original owner User 1. 
User 2 now has full owner-level privileges over this dashboard.


**Expected Result:**
The import process should enforce a secure workflow that prevents unauthorized users from altering original dashboards or claiming ownership.

If a user who is **not** an owner of a dashboard imports it, the system should create a copy of that dashboard. The user should be the owner of this new copy, but the original exported dashboard (owned by another user) should remain unchanged and unaffected.

Furthermore, for a user who is not an owner of the original dashboard, the option to ""Overwrite"" an existing dashboard during import should not be available or should be disabled. This prevents users from overwriting dashboards they do not own.

**Additional Notes:**
The ""can write on dashboard"" permission is intended to allow users to create and edit dashboards, should be seperated from possibility
to import dashboard.

### Screenshots/recordings

_No response_

### Superset version

4.1.3

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

previously this logic was added in https://github.com/apache/superset/pull/16656 


### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",propellerjet,5,dashboard:security:access,https://github.com/apache/superset/issues/36244,2025-11-24T21:15:25Z,,negative,bug,high
3659412912,36238,Sankey can't have same value for source and target,open,"### Bug description

Sankey is KO if value are same for source and target

<img width=""1892"" height=""750"" alt=""Image"" src=""https://github.com/user-attachments/assets/8fd818c6-bfb5-44b1-b2e9-d52297316cf8"" />

it's OK KO with different value for source and target

<img width=""1904"" height=""796"" alt=""Image"" src=""https://github.com/user-attachments/assets/c12235f6-ec8f-450d-b1bb-ded4bbfb5a1c"" />

### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [ ] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",xavier-GitHub76,4,viz:charts:sankey,https://github.com/apache/superset/issues/36238,2025-11-24T15:29:26Z,,negative,bug,medium
3658028499,36235,[6.0.0rc3] The dashboard list with thumbnails only shows 25 dashboards,open,"### Bug description

**Description:**
My Superset instance has 39 Dashboards. If I go to **my-domain.com/dashboard/list/** the list view shows 25 dashboards in the list and a second page with all remaining dashboards. 

If I switch to the tile/ thumbnail view 25 thumbnails are shown but there is no indication that there are more than 25 dashboards. 

**Expectation:**
If I view the dashboard list as thumbnails I am able to see all available dashboards on a single page or I am able to switch to the second page.



### Screenshots/recordings

<img width=""1719"" height=""1196"" alt=""Image"" src=""https://github.com/user-attachments/assets/47c7b41b-900a-4b04-9cbd-6692eac18f34"" />

<img width=""1716"" height=""1320"" alt=""Image"" src=""https://github.com/user-attachments/assets/25228eac-4cf7-43dc-92ef-dd82f130b617"" />

### Superset version

master / latest-dev

### Python version

I don't know

### Node version

I don't know

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",inazr,4,listview:dashboards,https://github.com/apache/superset/issues/36235,2025-11-24T09:50:15Z,,negative,bug,medium
3652511011,36224,Celery pods start generating Caching dashboard requests every second without errors or pauses,open,"### Bug description

The bug is with version 4.1.1.

For some dashboards, at random times, Celery pods start generating Caching dashboard requests every second without errors or pauses. Here is a sample log

_Caching dashboard: [https://<instance>:443/superset/dashboard/<dashboard](https://%3Cinstance%3E/superset/dashboard/%3Cdashboard) ID>_

This creates a lot of load on a Celery pod, which causes frequent restarts. 

The order of events:

1. Task cache_dashboard_thumbnail <thumbnail id> received
2. Caching dashboard: [https://<instance>:443/superset/dashboard/<dashboard](https://%3Cinstance%3E/superset/dashboard/%3Cdashboard) ID>/
3. Task cache_dashboard_thumbnail <thumbnail id> succeeded

And right after, we see

_Task cache_dashboard_thumbnail <new thumbnail ID> received_

... the cycle continues every second ... 

Sometimes the cycling stops on its own, but it can continue for a long period of time. 

We are looking for some clues on what could be triggering this behavior. 

This happens for published dashboards as well as drafts. We have not set any specific cache timeout setttings.

Is this a known issue? Are there any workarounds or fixes (without a version upgrade) to fix this issue?

### Screenshots/recordings

_No response_

### Superset version

4.1.3

### Python version

3.10

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [ ] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",ganeshvaidee,2,dashboard,https://github.com/apache/superset/issues/36224,2025-11-21T17:27:28Z,,negative,bug,high
3651567541,36223,Admin UI: allow administrators to change/reset another user's password,open,"### Bug description

Currently (using Superset 6.0.0rc2) there is no straightforward, documented way for a Superset admin to change or reset another user's password from the web UI. This makes account recovery and user management harder for operators and requires server-side or DB access to reset passwords.

### Why this matters
Operators and helpdesk staff need a safe in-product way to reset user passwords without direct DB edits or ad-hoc scripts. Relying on manual DB changes is error-prone and a security/operational burden.

### Expected behavior
In Security ‚Üí List Users (or on the ""edit users"" page), a site admin should be able to click ""Reset password"" (or similar), provide a new password, confirm and save; the user's password is updated and they can sign in with the new credentials

Optionally: audit log entry created when an admin changes someone else's password for traceability.

Action requires an Admin role (or a configurable permission).

### Workaround
(documented so admins can use it while the feature is implemented)

```
docker exec -it superset_app superset fab reset-password \
  --username ""Joe User"" --password ""password""
```


### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.10

### Node version

16

### Browser

Chrome

### Additional context

Superset Version 6.0.0rc2

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",ThomasBayen,3,authentication,https://github.com/apache/superset/issues/36223,2025-11-21T12:50:45Z,,negative,bug,high
3648954689,36213,6.0.0rc3: time grain isn't working for google bigquery datasets.,closed,"### Bug description

Using a BigQuery dataset, Time Grain does not work for BigQuery. It appears that the method that should inject the function name (e.g., DATE_TRUNC) into the string {func} is not being executed before sqlglot attempts to parse the query.

### Screenshots/recordings

Before applying time grain:

<img width=""1553"" height=""676"" alt=""Image"" src=""https://github.com/user-attachments/assets/da70a8a3-c27e-4fa7-9095-b63a0b56cd30"" />

After applying time grain:

<img width=""1584"" height=""533"" alt=""Image"" src=""https://github.com/user-attachments/assets/bc8c4b70-f522-4fc6-aa13-2d75b1c38d20"" />

All my charts in production using time grain are not working for v 6.0.0rc3:

<img width=""1842"" height=""861"" alt=""Image"" src=""https://github.com/user-attachments/assets/a2b5683b-79d3-463e-afe7-d3996b01ab1a"" />



### Superset version

master / latest-dev

### Python version

3.11

### Node version

18 or greater

### Browser

Firefox

### Additional context

The full log:

2025-11-20 14:20:09,848:WARNING:superset.views.error_handling:SupersetErrorException
Traceback (most recent call last):
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/superset/sql/parse.py"", line 563, in _parse
    statements = sqlglot.parse(script, dialect=dialect)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/.venv/lib/python3.11/site-packages/sqlglot/__init__.py"", line 102, in parse
    return Dialect.get_or_raise(read or dialect).parse(sql, **opts)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/.venv/lib/python3.11/site-packages/sqlglot/dialects/dialect.py"", line 1083, in parse
    return self.parser(**opts).parse(self.tokenize(sql), sql)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/.venv/lib/python3.11/site-packages/sqlglot/parser.py"", line 1624, in parse
    return self._parse(
           ^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/.venv/lib/python3.11/site-packages/sqlglot/parser.py"", line 1696, in _parse
    self.raise_error(""Invalid expression / Unexpected token"")
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/.venv/lib/python3.11/site-packages/sqlglot/parser.py"", line 1737, in raise_error
    raise error
sqlglot.errors.ParseError: Invalid expression / Unexpected token. Line 1, Col: 35.
  **SELECT {func}(`local_date`, DAY) AS `local_date`, count(DISTINCT imsi) AS `Sims_con_uso_46ddc`** 
FROM `esoteric-pad-360700`.`mosi`.`mosi

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/.venv/lib/python3.11/site-packages/flask/app.py"", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/.venv/lib/python3.11/site-packages/flask/app.py"", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/.venv/lib/python3.11/site-packages/flask_appbuilder/security/decorators.py"", line 109, in wraps
    return f(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/superset/views/base_api.py"", line 120, in wraps
    duration, response = time_function(f, self, *args, **kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/superset/utils/core.py"", line 1410, in time_function
    response = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/superset/utils/log.py"", line 304, in wrapper
    value = f(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/superset/charts/data/api.py"", line 260, in data
    return self._get_data_response(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/superset/utils/log.py"", line 304, in wrapper
    value = f(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/superset/charts/data/api.py"", line 422, in _get_data_response
    result = command.run(force_cached=force_cached)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/superset/commands/chart/data/get_data_command.py"", line 46, in run
    payload = self._query_context.get_payload(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/superset/common/query_context.py"", line 102, in get_payload
    return self._processor.get_payload(cache_query_context, force_cached)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/superset/common/query_context_processor.py"", line 1062, in get_payload
    query_results = [
                    ^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/superset/common/query_context_processor.py"", line 1063, in <listcomp>
    get_query_results(
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/superset/common/query_actions.py"", line 232, in get_query_results
    return result_func(query_context, query_obj, force_cached)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/superset/common/query_actions.py"", line 108, in _get_full
    payload = query_context.get_df_payload(query_obj, force_cached=force_cached)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/superset/common/query_context.py"", line 123, in get_df_payload
    return self._processor.get_df_payload(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/superset/common/query_context_processor.py"", line 165, in get_df_payload
    query_result = self.get_query_result(query_obj)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/superset/common/query_context_processor.py"", line 280, in get_query_result
    result = query_context.datasource.query(query_object.to_dict())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/superset/connectors/sqla/models.py"", line 1641, in query
    df = self.database.get_df(
         ^^^^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/superset/models/core.py"", line 679, in get_df
    script = SQLScript(sql, self.db_engine_spec.engine)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/superset/sql/parse.py"", line 1243, in __init__
    self.statements = statement_class.split_script(script, engine)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/superset/sql/parse.py"", line 603, in split_script
    cls(ast=ast, engine=engine) for ast in cls._parse(script, engine) if ast
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/media/mako/files/proj/py/smart/apache_superset-6.0.0rc3/superset/sql/parse.py"", line 574, in _parse
    raise SupersetParseError(script, engine, **kwargs) from ex
superset.exceptions.SupersetParseError: Error parsing near 'AS' at line 1:35

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",bihazmx,3,"validation:required, data:connect:googlebigquery, release:blocker",https://github.com/apache/superset/issues/36213,2025-11-20T20:26:48Z,2025-11-21T21:32:41Z,negative,bug,high
3648208576,36212,6.0.0rc2 : unable to save dataset - table 'tagged_object' missing 'dataset' type in 'object_type' enum after migration from previous version,open,"### Bug description

I tried superset 6.0.0rc2, migrated from 4.x).

When creating a new dataset, I encounterd an error popup telling me Dataset could not be created.

Digging in the logs I found

```
packages/MySQLdb/connections.py"", line 265, in query
    _mysql.connection.query(self, query)
MySQLdb.IntegrityError: (1062, ""Duplicate entry '6-942-' for key 'tagged_object.uix_tagged_object'"")

blablabla

[SQL: INSERT INTO tagged_object (created_on, changed_on, tag_id, object_id, object_type, created_by_fk, changed_by_fk) VALUES (%s, %s, %s, %s, %s, %s, %s)]
[parameters: (datetime.datetime(2025, 11, 20, 16, 27, 11, 647065), datetime.datetime(2025, 11, 20, 16, 27, 11, 647070), 6, 942, 'dataset', 2, 2)]

```

SO ... I had a look at the database, it did not contain any matching data.

After investigation, I found that the column `object_type` of the table `tagged_object` is an enum, and the possibles values where `enum('query','chart','dashboard')`


If I manually add the value `dataset` to the enum , then I can create new datasets. That's ok as a workaround I guess ?

My guess is that the migration script did not alter the existing table.


### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.10

### Node version

I don't know

### Browser

Safari

### Additional context

The database I use has been migrated from superset 3.1.0 to 4.x then to 6.0.0rc2

so maybe an intermediary migration script is missing somehow.

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",squalou,3,data:databases,https://github.com/apache/superset/issues/36212,2025-11-20T17:03:26Z,,negative,bug,high
3647987969,36211,"6.0.0rc3 - Unable to create a dashboard when DYNAMIC_PLUGINS is set to ""true""",open,"### Bug description

In the ""superset_config.py"" file, when the configuration parameter is set as follows ""DEFAULT_FEATURE_FLAGS = {""DYNAMIC_PLUGINS"": True,}"", I can‚Äôt add a new dashboard. The page goes on hold indefinitively and my console displays the following message:

<img width=""1074"" height=""314"" alt=""Image"" src=""https://github.com/user-attachments/assets/8ec520ce-4b14-4164-b8a8-2e971b4a209c"" />

When I set """"DYNAMIC_PLUGINS"": False"", everything works perfectly.

Ticket #35870 mentions that DYNAMIC_PLUGINS is a beta feature. I imagine that this problem is well known and will be corrected with the ""Extensions"" function?

### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.9

### Node version

18 or greater

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",SupersetOdT,5,dashboard,https://github.com/apache/superset/issues/36211,2025-11-20T16:12:06Z,,negative,bug,high
3646942270,36204,Embedded Dashboard ignores spacing between charts,open,"### Bug description

I have embedded the Sales Dashboard Demo in a test angular application using the superset embedded sdk. The embedded Dashboard is not showing me the same spacing as the original Dashboard.

Original: Has spacing between all charts

<img width=""2558"" height=""1140"" alt=""Image"" src=""https://github.com/user-attachments/assets/d5bf5d69-b909-49f4-82f2-a7e64590af49"" />

Embedded: No Spacing between charts and unnecessary horizontal scrollbar:

<img width=""1944"" height=""1084"" alt=""Image"" src=""https://github.com/user-attachments/assets/b26a27f0-47bc-4ccb-b7cd-8167681b53b8"" />

### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

I don't know

### Node version

16

### Browser

Firefox

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",NeBene,6,"#bug:cosmetic, embedded",https://github.com/apache/superset/issues/36204,2025-11-20T11:57:28Z,,negative,bug,medium
3643461333,36189,Percentage number formatting in table not working on very small numbers in 5.0.0,open,"### Bug description

Percentage formatting for very small numbers is not applied.  The result of attempts to format very small numbers as percentages is that no format is applied and the raw number is returned.

It seems what triggers this is a case in which some of the numbers are very small, but non-zero.  If so, all formatting breaks for the column and even larger numbers are not formatted correctly.


E.g.
`-0.00001229` with D3 format `.8%` and Small number format `.8%` will just return the raw value. `-0.00001229`.

<img width=""532"" height=""503"" alt=""Image"" src=""https://github.com/user-attachments/assets/4c83bf30-f9e0-4eb5-89a3-78dc7cb00724"" />


It doesn't matter what percentage format is applied.  It fails if the attempted format is `.4%` or `.2%` as well.

Here's a link to the Slack conversation I had about this with the AI bots:
https://apache-superset.slack.com/archives/C072KSLBTC1/p1763566767804459

There is mention of similar issues with number/currency formatting but nothing relating to percentage formatting specifically.

### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",rea725,2,"good first issue, viz:charts:table, ü¶æ ai-candidate",https://github.com/apache/superset/issues/36189,2025-11-19T16:15:15Z,,negative,bug,medium
3642792355,36186,Requests to /superset/log cause redirect to /login (Embedded SDK),closed,"### Bug description

### Issue

Using the Devtools in the browser, we're seeing regular requests to `/superset/log?explode=events` that are 302 redirected to `/login/?next=http://superset.application.example.org/superset/log/?explode=events`. This is an issue because we restrict access to the `/login` path, thus resulting in 403 errors. Other than that, the dashboards seem to work correctly.

### Expected behavior

Requests to `/superset/log?explode=events` are directly processed with a 200 OK.

### Details

We have integrated Superset dashboards with our application using the Embedded SDK. Superset is provided on a subdomain (say ""superset.application.example.org"" to our application domain ""application.example.org"").

The corresponding settings for Embedding, CSP, etc. were set (see `superset_config.py` below). In the version we use, there should be no issues with an empty `WTF_CSRF_EXEMPT_LIST` as in [issue 30717](https://github.com/apache/superset/issues/30717). Checking the request headers, `X-CSRFToken` is set on other requests and missing on `/superset/log`... which to my understanding is the correct behavior.

I tried to get extensive logging using the environment variable `FLASK_DEBUG: True`, but there's no issues reported (expect for the notorious [Class 'werkzeug.local.LocalProxy' is not mapped](https://github.com/apache/superset/issues/26020)). In addition, I tried to set the correct `WTF_CSRF_EXEMPT_LIST` explicitly without effect.

### Screenshots/recordings

_No response_

### Superset version

5.0.0

### Python version

3.10

### Node version

Not applicable

### Browser

Firefox

### Additional context

We're running Superset 5.0.0 in Kubernetes (with a custom Docker image: official image plus `psycopg2`). Superset was installed via Helm Chart 0.15.0.

I want to avoid spamming with the complete `values.yaml`, thus only the `superset_config.py` and environment variables in the following.

### /app/pythonpath/superset_config.py

```
import os
from flask_caching.backends.rediscache import RedisCache

def env(key, default=None):
    return os.getenv(key, default)

# Redis Base URL
REDIS_BASE_URL=f""{env('REDIS_PROTO')}://{env('REDIS_HOST')}:{env('REDIS_PORT')}""

# Redis URL Params
REDIS_URL_PARAMS = """"

# Build Redis URLs
CACHE_REDIS_URL = f""{REDIS_BASE_URL}/{env('REDIS_DB', 1)}{REDIS_URL_PARAMS}""
CELERY_REDIS_URL = f""{REDIS_BASE_URL}/{env('REDIS_CELERY_DB', 0)}{REDIS_URL_PARAMS}""

MAPBOX_API_KEY = env('MAPBOX_API_KEY', '')
CACHE_CONFIG = {
      'CACHE_TYPE': 'RedisCache',
      'CACHE_DEFAULT_TIMEOUT': 300,
      'CACHE_KEY_PREFIX': 'superset_',
      'CACHE_REDIS_URL': CACHE_REDIS_URL,
}
DATA_CACHE_CONFIG = CACHE_CONFIG

SQLALCHEMY_DATABASE_URI = f""postgresql+psycopg2://{env('DB_USER')}:{env('DB_PASS')}@{env('DB_HOST')}:{env('DB_PORT')}/{env('DB_NAME')}""
SQLALCHEMY_TRACK_MODIFICATIONS = True

class CeleryConfig:
  imports  = (""superset.sql_lab"", )
  broker_url = CELERY_REDIS_URL
  result_backend = CELERY_REDIS_URL

CELERY_CONFIG = CeleryConfig
RESULTS_BACKEND = RedisCache(
      host=env('REDIS_HOST'),
      port=env('REDIS_PORT'),
      key_prefix='superset_results',
)

# Overrides
GUEST_ROLE_NAME = ""Embedded""  # Custom role
GUEST_TOKEN_JWT_SECRET = env('GUEST_TOKEN_JWT_SECRET')
GUEST_TOKEN_JWT_EXP_SECONDS = 300  # 5 minutes
TALISMAN_CONFIG = {
    ""content_security_policy"": {
        ""frame-ancestors"": [""'self'"", ""https://application.example.org/""],
        ""base-uri"": [""'self'""],
        ""default-src"": [""'self'""],
        ""img-src"": [""'self'"", ""blob:"", ""data:""],
        ""worker-src"": [""'self'"", ""blob:""],
        ""connect-src"": [""'self'""],
        ""object-src"": ""'none'"",
        ""style-src"": [""'self'"", ""'unsafe-inline'""],
        ""script-src"": [""'self'"", ""'strict-dynamic'""],
    },
    ""content_security_policy_nonce_in"": [""script-src""],
    ""force_https"": False,
    ""session_cookie_secure"": False,
}
TALISMAN_DEV_CONFIG = TALISMAN_CONFIG
FEATURE_FLAGS = {
    ""EMBEDDED_SUPERSET"": True,
    ""EXTRA_CATEGORICAL_COLOR_SCHEMES"": True
}
LANGUAGES = {
    ""en"": {""flag"": ""us"", ""name"": ""English""},
    ""de"": {""flag"": ""de"", ""name"": ""German""}
}
CACHE_CONFIG = {
    ""CACHE_TYPE"": ""SimpleCache"",  # Local in-memory cache
    ""CACHE_DEFAULT_TIMEOUT"": 86400  # 1 day in seconds
}
DATA_CACHE_CONFIG = CACHE_CONFIG

# Do not use async queries (requiring Redis)
CELERY_CONFIG = None
RESULTS_BACKEND = None

EXTRA_CATEGORICAL_COLOR_SCHEMES = [
    [‚Ä¶ omitted ‚Ä¶]
]
```

### Environment variables

These are the additional environment variables with most values redacted.

```
  DB_HOST: <external Postgres>
  DB_NAME: superset_integ
  DB_PASS: <‚Ä¶>
  DB_PORT: 5432
  DB_USER: superset_integ
  GUEST_TOKEN_JWT_SECRET: <custom secure secret>
  REDIS_HOST: dummy
  SUPERSET_ADMIN_EMAIL: <‚Ä¶>
  SUPERSET_ADMIN_FIRSTNAME: <‚Ä¶>
  SUPERSET_ADMIN_LASTNAME: <‚Ä¶>
  SUPERSET_ADMIN_PASS: <‚Ä¶>
  SUPERSET_ADMIN_USER: <‚Ä¶>
  SUPERSET_PORT=8088
  SUPERSET_SECRET_KEY: <custom secure key>
```

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",akerkau,6,"validation:required, authentication, embedded",https://github.com/apache/superset/issues/36186,2025-11-19T13:40:24Z,2025-11-20T09:49:40Z,negative,bug,medium
3642595544,36185,Table Headers with two metrics and time shift are bad aligned,open,"### Bug description

The formatting of table chart headers is bad aligned if you use metrics and time comparison. It looks crazy. The added screenshot explains it best.

To explain if the screenshort is not obvious for you: This table chart has two metrics (""HL Summe"" and ""‚Ç¨ Summe"") and for each an additional column for last year's amount. Afaiu the table header should have two lines. One thing is that all four columns (in the lower header line) seem to be collected under the first entry in the upper header line. That is wrong. The second thing is that all header columns are in no way aligned to the table columns below the header.

### Screenshots/recordings

<img width=""1076"" height=""308"" alt=""Image"" src=""https://github.com/user-attachments/assets/b7419591-15a9-45d6-81d0-de3af4b94140"" />

### Superset version

master / latest-dev

### Python version

3.10

### Node version

16

### Browser

Chrome

### Additional context

I use superset 6.0.0rc2 and I am not sure if I have to install the master branch to file a bug report. Sorry if this is already solve somewhere else but I did not find a ticket for it.

The server is a docker image on Debian Trixie and the Browser is actual Google Chrome on Debian Trixie/XFCE4.

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",ThomasBayen,4,"#bug:cosmetic, viz:charts:table",https://github.com/apache/superset/issues/36185,2025-11-19T12:51:47Z,,negative,bug,medium
3642136725,36183,I am unable to connect MSSQL in Superset. Superset always shows this error,closed,"### Bug description

I am unable to connect MSSQL in Superset. Superset always shows this error:
ERROR: Could not load database driver: MssqlEngineSpec.
After checking deeply, I found that the latest Superset versions use SQLAlchemy 2.x, and SQLAlchemy 2.x has removed the MSSQL+pymssql dialect, so Superset cannot load the MSSQL engine anymore. Also, pymssql fails to install on all modern Docker images (Python ‚â• 3.10, Debian 12) and Microsoft ODBC Driver 18 does not install on Debian 12. Because of all these issues, MSSQL is currently not supported in the newer Superset versions. Please confirm if MSSQL support has been officially dropped or if there is any recommended workaround to use MSSQL with Superset.

### Screenshots/recordings

<img width=""1909"" height=""815"" alt=""Image"" src=""https://github.com/user-attachments/assets/ca6b06e2-f435-49e3-b32d-9ebc39b28873"" />

### Superset version

4.1.3

### Python version

3.9

### Node version

I don't know

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",damodhar-admin,6,"validation:required, data:connect:mssql",https://github.com/apache/superset/issues/36183,2025-11-19T10:44:33Z,2025-11-19T16:54:06Z,negative,bug,high
3636684219,36165,Table Visual Summary value not matching,open,"### Bug description

 I'm seeing inconsistent totals between a Pie Chart and a Table visualization in the same Superset dashboard. Both are using the same metrics and filters.
In the Table visualization:
If I export/copy the table and manually sum the values, the total is correct.
But the summary total shown in the table is incorrect for 
some charts.
In the Pie Chart visualization:
The total value displayed does not match the correct total from the table.
It seems like Superset is calculating totals differently between the pie chart and the table summary, or the table summary is aggregating incorrectly.


In the attached image, the summary shows 34610, but when we add manually it gives 37890

![Image](https://github.com/user-attachments/assets/3211856e-65d5-4c46-ac88-2edc7bb346da)

### Screenshots/recordings

_No response_

### Superset version

4.1.3

### Python version

3.9

### Node version

16

### Browser

Not applicable

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",ramana-pb,5,validation:required,https://github.com/apache/superset/issues/36165,2025-11-18T08:01:52Z,,negative,bug,high
3636572679,36159,I have Created Botton Date Filter Button not applying filter on Dashboard,closed,"### Bug description

I have implemented a Custom Filter Component (not using the built-in Native Filters) on the dashboard header, visible as a date button (e.g., 18-11-2025) next to the ""Edit dashboard"" button. This component uses a modal to allow the user to select a time range.
Expected Behavior:
When a user selects a new date range (e.g., 2025-11-01 to 2025-11-08) from the Custom Component's modal and clicks 'Apply Filter', the Custom Component's state should be successfully written to the dashboard's global filter state.
The dashboard should then detect this state change and automatically trigger a refresh for all affected charts (e.g., ""Count Product,"" ""Details Table Chart""), using the new filter values.
Actual Behavior:
The Custom Filter Component successfully captures the new date range internally (e.g., 2025-11-01 to 2025-11-08). However, this new filter state is not being successfully broadcast to the rest of the dashboard. The charts do not refresh or change and continue to display data based on the old date/filter (e.g., up to 2025-11-18).

[Environment_Details.xlsx](https://github.com/user-attachments/files/23599797/Environment_Details.xlsx)

### Screenshots/recordings

![Image](https://github.com/user-attachments/assets/703366ba-c3a0-45dd-8632-41122b0c432b)

![Image](https://github.com/user-attachments/assets/3bf0011d-12a3-494f-88be-a7462fbe74eb)

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",prathameshdarekar0001-stack,3,dashboard:filtersets,https://github.com/apache/superset/issues/36159,2025-11-18T07:32:18Z,2025-11-18T18:13:51Z,negative,bug,high
3635199228,36145,[SIP-192] Labeled Version History + Restore,open,"## [SIP] Proposal for Labeled Version History + Restore

### Motivation

Some users want to be able to roll back and have a process to save states of their virtual datasets or other assets.

It was mentioned here also https://github.com/apache/superset/issues/30436 that some people were talking about opening a SIP already, not sure if i missed it, but I couldn't find it after looking for one, so I'll assume it wasn't done and people still want something like this

### Proposed Change
In each of the Dashboard/Chart/Dataset edit properties modal, I plan to have a version history button at the bottom:
<img width=""888"" height=""944"" alt=""Image"" src=""https://github.com/user-attachments/assets/141133ee-301e-4dd8-8817-288e43a511d3"" />
<img width=""933"" height=""799"" alt=""Image"" src=""https://github.com/user-attachments/assets/e41e4110-6740-4e16-adba-3d8418891de0"" />
<img width=""879"" height=""945"" alt=""Image"" src=""https://github.com/user-attachments/assets/290f5c7c-f6b8-489a-8a2b-c726e3ce4261"" />

Once clicked, It will show all the versions that you have saved and provide an option for you to save a new one:
<img width=""735"" height=""296"" alt=""Image"" src=""https://github.com/user-attachments/assets/82a670bf-3590-413c-90ce-53f012432a3d"" />

If you chose to save a new one you get this popup and a choice to save a named version:
<img width=""618"" height=""285"" alt=""Image"" src=""https://github.com/user-attachments/assets/5955dc91-3277-4209-a46d-db6164321d14"" />

Clicking on a version, you get the option to restore:
<img width=""786"" height=""458"" alt=""Image"" src=""https://github.com/user-attachments/assets/f2fd69ac-ac78-4582-9f85-d75c8bf215d6"" />

Here are some end to end examples I've recorded
Datasets:
![Image](https://github.com/user-attachments/assets/09369199-0029-4d2c-b46a-ae70ad2c6d62)

Charts:
![Image](https://github.com/user-attachments/assets/77a24bc8-f136-4114-9da8-d4879b4956fa)

Dashboards:
![Image](https://github.com/user-attachments/assets/9dccad43-ed8a-4cf0-86e5-123edf60a7c0)

Not shown work that I'd still probably need to do would be deleting of versions or having a # of versions cap per asset (dashboard, chart, dataset) perhaps configurable in the config.

This uses the import/export stuff that already exists for now with a few modifications.

Some extra notes about breaking changes between ""Version history"". There are cases which I have come up with that cause things to look broken (intended). My approach and thought is that if the asset was in the version restored, would it have broken with changes anyways? 

For example, we have a chart version say 0, and now it's changed a whole bunch but we need to bring back chart 0. In the current state, it uses Dataset 1*, but it used to use Dataset 1 (Changes were made to dataset1, that were breaking). If we restore the dataset to version 0, it is no longer compatible with the dataset, and breaking, however, had the chart been left in first place, it would have been broken anyways. This thinking applies here: 

Reverting dataset can change Charts. There is a warning when doing it manually, same thing applies. Should you revert a dataset to a breaking version, the charts that relied in the current state will break too.

Chart reverts will ALSO appear on dashboards. Makes sense, but something users should consider when reverting, they're basically changing the same chart change

Dashboard is where it gets a little more intricate and perhaps users will experience the most unexpected behaviours while still following the design of ""reverts will be as if no edits were made"":
The charts will not be the ones saved on current versions. I can think of 2 main odd scenarios.
1. Chart is deleted. It will show up on the dashboard with the deleted chart error. If any dashboard's chart is deleted, it'll show the same thing anyways. If the dashboard was never modified and the chart was deleted, it would show the same error
2. Changed charts. A chart that was changed from when the version was made to the time it was restored, it would show the new changed one. Again, if the dashboard was never modified, the chart would appear also changed.

### New or Changed Public Interfaces

Probably will need at least a new set of endpoints to for the endpoints.
Listing version, Saving Versions and Restoring Versions:

```
@expose(""/<asset_type>/<int:asset_id>/save"", methods=[""POST""])
    def save_version(self, asset_type: str, asset_id: int) -> Response:

@expose(""/<asset_type>/<int:asset_id>/list"", methods=[""GET""])
    def list_versions(self, asset_type: str, asset_id: int) -> Response:

@expose(""/<asset_type>/<int:asset_id>/restore"", methods=[""POST""])
    def restore_version(self, asset_type: str, asset_id: int) -> Response:

```

Sort of depending on the implementation, we'd probably need a version model to have a clean implementation for accessing this stuff. I know some people want this stored on git(??) more about this in Migration Plan and Compatibility.

For deployment, I think if we end up having a configurable max cap per asset, probably a variable needs to be set with a default for deployment?
IF GIT IS USED, a token and a repo should be provided.

### New dependencies

Git packages? depends on what people want and what makes the most sense

### Migration Plan and Compatibility

I think ideally a new table should be creating with the versions:
| Asset_Type | Asset_ID | Version_number | Description_of_version

The DB upgrade with create the table and since it's use solely for the history, downgrading will just be deleting the table. Since nothing will use the table I dont think deleting the table on downgrade will affect anything.

HOWEVER, the git storage would provide users with a way to edit and create versions outside of superset, and have a full approval process system where they could have a supervisor or something review changes to datasets. I dont know if this is the best thing to do, but it's on the table when discussing with other people

",ethan-l-geotab,11,"sip, design:proposal",https://github.com/apache/superset/issues/36145,2025-11-17T21:45:42Z,,neutral,feature_request,medium
3634129072,36139,Rolling the Secret Key in a Kubernetes environment is not working for me.,closed,"### Bug description

I originally set up a metadatabase using Docker Compose. In that environment, I rolled the key once without any issues.
Now we are deploying Superset in Kubernetes.

I tried following the documented process for rolling the secret key.

configOverrides:
  my_override: |
    PREVIOUS_SECRET_KEY = 'YOUR_PREVIOUS_SECRET_KEY'
    SECRET_KEY = 'YOUR_OWN_RANDOM_GENERATED_SECRET_KEY'
init:
  command:
    - /bin/sh
    - -c
    - |
      . {{ .Values.configMountPath }}/superset_bootstrap.sh
      superset re-encrypt-secrets
      . {{ .Values.configMountPath }}/superset_init.sh

When running superset re-encrypt-secrets, no error logs appear.
However, the init command exits with an error code, stating that the decryption key is invalid.
I also cannot use the application anymore‚Äîit shows ‚Äúinvalid decryption key‚Äù errors. Inside the Superset shell, both the old and new values for SECRET_KEY and PREVIOUS_SECRET_KEY are correct.

I also tried skipping the init script and performing the key rotation during runtime inside the Superset container. I let Python read the values from the environment variables and set them via the console. The Superset shell again returns the correct values. But when I access the application, I still get ‚Äúwrong decryption key‚Äù errors.

If you need any more information about our setup, please let me know.

### Screenshots/recordings

_No response_

### Superset version

5.0.0

### Python version

I don't know

### Node version

I don't know

### Browser

Firefox

### Additional context

_No response_

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",TobSchwa94,2,,https://github.com/apache/superset/issues/36139,2025-11-17T16:44:55Z,2025-11-18T18:06:20Z,negative,bug,high
3632501465,36132,Anchors don't work in Embedded dashboards,open,"### Bug description

Repro steps: 
1. Generate a permalink key by clicking on anchor btn on a tab
2. Embed a dashboard using the sdk 
```javascript
supersetEmbeddedSdk.embedDashboard({
        id: EMBED_DASHBOARD_ID,
        supersetDomain: ""http://ip"",
        mountPoint: document.getElementById(""cont""), // any html element that can contain an iframe
        fetchGuestToken: () => fetchGuestTokenFromBackend(),
        dashboardUiConfig: {
          // dashboard UI config: hideTitle, hideTab, hideChartControls, filters.visible, filters.expanded (optional), urlParams (optional)
          hideTitle: false,
          hideTab: false,
          hideChartControls: false,
          filters: {
            visible: true,
            expanded: true,
          },
          urlParams: {
            permalink_key: ""KEY GOES HERE"",
          },
        },
        iframeSandboxExtras: [
          ""allow-top-navigation"",
          ""allow-popups-to-escape-sandbox"",
        ],
      });
```

Expected behaviour: Tab gets selected, dashboard content switches to that tab.
Actual behaviour: Tab gets selected but you always get the content of the 1st dashboard.
Possible regression caused by #31194

### Screenshots/recordings

```json
{
    ""activeTabs"": [
        ""TAB-Bpy2E5tgu""
    ],
    ""anchor"": ""TAB-Bpy2E5tgu"",
    ""urlParams"": []
}

```
this is the content of the permalink request, as you can see activeTabs gets applied but not anchor.
I also tried 4.0.0 where the PR wasn't merged yet and the anchor element with tab id was still there but still same behaviour was there.
No stacktrace no console logs.

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",Rattlyy,6,"dashboard:tab, embedded",https://github.com/apache/superset/issues/36132,2025-11-17T09:35:00Z,,negative,bug,high
3632079645,36130,"6.0.0rc2-Security-Base Permissions and Permission on Views/Menus click ""Internal server error""",open,"### Bug description

VersionÔºö6.0.0rc2
OperationÔºöSettings->Manage->Plugins->Security->Base Permissions  or  Permission on Views/Menus
Incorrectly operated routeÔºö/permissions/list/, /permissionviews/list/
Other descriptionsÔºöThese two functions are normal in other versions, but clicking on them is incorrect in this version. Have there been any other destructive changes or configurations?
       

### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.11

### Node version

18 or greater

### Browser

Chrome

### Additional context

This is the background log when you click ""Base Permissions""Ôºö
2025-11-17 15:25:22,090:WARNING:superset.views.error_handling:Exception
Traceback (most recent call last):
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask\app.py"", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask\app.py"", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\security\decorators.py"", line 151, in wraps
    return f(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\views.py"", line 205, in list
    return self.render_template(
           ^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\baseviews.py"", line 346, in render_template
    return render_template(
           ^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask\templating.py"", line 151, in render_template
    return _render(app, template, context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask\templating.py"", line 132, in _render
    rv = template.render(context)
         ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\jinja2\environment.py"", line 1295, in render
    self.environment.handle_exception()
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\jinja2\environment.py"", line 942, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\templates\appbuilder\general\model\list.html"", line 2, in top-level template code
    {% import 'appbuilder/general/lib.html' as lib %}
    ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\templates\appbuilder\base.html"", line 1, in top-level template code
    {% extends base_template %}
    ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\templates\appbuilder\baselayout.html"", line 2, in top-level template code
    {% import 'appbuilder/baselib.html' as baselib %}
    ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\templates\appbuilder\init.html"", line 42, in top-level template code
    {% block body %}
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\templates\appbuilder\baselayout.html"", line 19, in block 'body'
    {% block content %}
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\templates\appbuilder\general\model\list.html"", line 13, in block 'content'
    {% block list_list scoped %}
    ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\templates\appbuilder\general\model\list.html"", line 15, in block 'list_list'
    {{ widgets.get('list')()|safe }}
    ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\widgets.py"", line 33, in __call__
    template = jinja_env.get_template(self.template)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask\templating.py"", line 64, in get_source
    return self._get_source_fast(environment, template)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask\templating.py"", line 98, in _get_source_fast
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: superset/fab_overrides/list.html
2025-11-17 15:25:22,091:ERROR:superset.views.error_handling:superset/fab_overrides/list.html
Traceback (most recent call last):
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask\app.py"", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask\app.py"", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\security\decorators.py"", line 151, in wraps
    return f(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\views.py"", line 205, in list
    return self.render_template(
           ^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\baseviews.py"", line 346, in render_template
    return render_template(
           ^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask\templating.py"", line 151, in render_template
    return _render(app, template, context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask\templating.py"", line 132, in _render
    rv = template.render(context)
         ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\jinja2\environment.py"", line 1295, in render
    self.environment.handle_exception()
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\jinja2\environment.py"", line 942, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\templates\appbuilder\general\model\list.html"", line 2, in top-level template code
    {% import 'appbuilder/general/lib.html' as lib %}
    ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\templates\appbuilder\base.html"", line 1, in top-level template code
    {% extends base_template %}
    ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\templates\appbuilder\baselayout.html"", line 2, in top-level template code
    {% import 'appbuilder/baselib.html' as baselib %}
    ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\templates\appbuilder\init.html"", line 42, in top-level template code
    {% block body %}
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\templates\appbuilder\baselayout.html"", line 19, in block 'body'
    {% block content %}
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\templates\appbuilder\general\model\list.html"", line 13, in block 'content'
    {% block list_list scoped %}
    ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\templates\appbuilder\general\model\list.html"", line 15, in block 'list_list'
    {{ widgets.get('list')()|safe }}
    ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask_appbuilder\widgets.py"", line 33, in __call__
    template = jinja_env.get_template(self.template)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask\templating.py"", line 64, in get_source
    return self._get_source_fast(environment, template)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\superset-dev\superset-60-env\Lib\site-packages\flask\templating.py"", line 98, in _get_source_fast
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: superset/fab_overrides/list.html
2025-11-17 15:25:22,094 INFO sqlalchemy.engine.Engine ROLLBACK
2025-11-17 15:25:22,094:INFO:sqlalchemy.engine.Engine:ROLLBACK
2025-11-17 15:25:22,121:INFO:werkzeug:127.0.0.1 - - [17/Nov/2025 15:25:22] ""GET /permissions/list/ HTTP/1.1"" 500 -

### Checklist

- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [x] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",YizhiDu,3,authentication,https://github.com/apache/superset/issues/36130,2025-11-17T07:26:40Z,,negative,bug,high
3631845900,36129,Slack API issue - Reports not being generated,open,"### Bug description

Since the files_upload api is being deprecated by Superset, I have found many reports are not being published properly. So we need to either remove the slack_api code or we need to add an try except to use files_upload_v2 in place of files_upload

### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [ ] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",slice-swayams,2,alert-reports,https://github.com/apache/superset/issues/36129,2025-11-17T05:50:31Z,,negative,bug,high
3627617383,36124,Newly created dataset doesn't show up in dashboard filter creation dropdown,closed,"### Bug description

Repro steps:

Start in an instance with 100+ datasets created 
    1. Create a new dataset (I created a physical dataset)
    2. Go to a dashboard
    3. Go to add/edit a filter
    4. Pick a filter type (I used value filter)
    5. In the dataset list, search for your new dataset

Current behavior:
New dataset doesn't appear in the list
Renaming the dataset to a_name will get it to appear 

### Screenshots/recordings

_No response_

### Superset version

master / latest-dev

### Python version

3.9

### Node version

16

### Browser

Chrome

### Additional context

_No response_

### Checklist

- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.
- [ ] I have searched the GitHub issue tracker and didn't find a similar bug report.
- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the ""additional context"" section.",yousoph,3,dashboard:filtersets,https://github.com/apache/superset/issues/36124,2025-11-15T00:23:50Z,2025-11-19T23:18:03Z,negative,bug,medium
3625365053,36117,"Remote user auth (AUTH_REMOTE_USER) worked well in 5.0.0, experienced issues with 6.0.0rc2",open,"### Bug description

I did not have much success trying to setup REMOTE_AUTH in Superset 6.0.0 (rc2), in the end I reverted to 5.0.0 and it worked immediately (with config as in `superset_config.py` below). Could this be a regression bug (or breaking change)?

```from flask_appbuilder.security.manager import AUTH_REMOTE_USER
AUTH_TYPE = AUTH_REMOTE_USER
AUTH_REMOTE_USER_ENV_VAR = 'HTTP_X_AUTH_REQUEST_EMAIL'
AUTH_USER_REGISTRATION = False
```

(used standard docker image 6.0.0rc and 5.0.0 respectively)",hoogenm,4,authentication,https://github.com/apache/superset/issues/36117,2025-11-14T12:16:29Z,,negative,bug,medium
3625289971,36116,[SIP-191] Proposal for Improving Import Error Logging for Dashboard/Chart ZIP Imports,open,"## [SIP] Proposal for Improved Error Reporting During Dashboard/Chart Import Validation

### Motivation

Currently, when importing dashboards or charts using the Superset Import API, any validation failure or metadata mismatch inside the import bundle results in opaque error messages such as:
~~~
Import dashboard failed for an unknown reason
~~~


The server logs contain a generic stack trace like:

KeyError: 580


‚Ä¶but the API response and UI do not expose which part of the import bundle is invalid.

This makes it difficult to debug problems such as:
- Mismatched IDs in `filter_scopes`
- Missing chart references in dashboard metadata
- Broken or outdated metadata produced by older Superset versions
- Incorrect ZIP structure

Users must manually inspect YAML/JSON inside the ZIP‚Äîsomething that is error-prone and slow.

Improving the error messages will significantly reduce debugging time and make import flows more predictable for developers.

---

### Proposed Change

1. Add Proper Aggregated Validation Error Logging

The current code in `superset/commands/importers/v1/assets.py` catches a list of validation exceptions but logs almost nothing, emitting only:

Import dashboard failed for an unknown reason


This proposal introduces structured, explicit error logging for each validation exception.

### Proposed implementation

Below is a production-aligned rewrite of the snippet the author experimented with:

```python
# superset/commands/importers/v1/assets.py

import logging
logger = logging.getLogger(__name__)

if exceptions:
    for exc in exceptions:
        # Log each validation exception clearly with details
        logger.error(
            ""Import validation error: %s | details: %s"",
            str(exc),
            getattr(exc, ""messages"", None)
        )

    # Raise a domain-specific error containing the full list
    raise CommandInvalidError(
        ""Error importing assets due to validation failures"",
        exceptions=exceptions,
    )
```

Improvements over the experimental version

- Uses logger (Superset convention) instead of logging

- Clearer message formatting

- Includes both the exception itself and its .messages attribute (if any)

- Raises a more descriptive CommandInvalidError

- Matches the surrounding command architecture in other importers

## Return Descriptive Error Messages via API

Example API response:

~~~
{
  ""error"": ""ImportValidationError"",
  ""errors"": [
    {
      ""message"": ""Chart ID 580 referenced in filter_scopes does not exist."",
      ""exception_type"": ""KeyError""
    }
  ]
}
~~~


### New or Changed Public Interfaces
API Responses

Import-related endpoints will now return:

More detailed error messages

Structured lists of validation failures

This is backward compatible because:

The HTTP code remains the same

Existing clients that ignore details remain unaffected

CLI (superset import-*)

The CLI will print the same improved messages, giving developers immediate insight into metadata issues.

No CLI flags or config changes required.

### New dependencies

None

### Migration Plan and Compatibility
No migrations required.

### Rejected Alternatives

1. Only improving server logs, not API responses

Many users run imports in CI/CD pipelines or via automated scripts and do not have access to server logs.",deeshantk,2,"sip, dashboard:import, design:proposal",https://github.com/apache/superset/issues/36116,2025-11-14T11:53:22Z,,positive,feature_request,medium
